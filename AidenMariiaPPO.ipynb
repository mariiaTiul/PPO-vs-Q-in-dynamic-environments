{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88dfdf78-932f-45de-a762-0b6223b84b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'ViZDoom'...\n",
      "Updating files:  33% (686/2058)\n",
      "Updating files:  34% (700/2058)\n",
      "Updating files:  35% (721/2058)\n",
      "Updating files:  36% (741/2058)\n",
      "Updating files:  37% (762/2058)\n",
      "Updating files:  38% (783/2058)\n",
      "Updating files:  39% (803/2058)\n",
      "Updating files:  40% (824/2058)\n",
      "Updating files:  41% (844/2058)\n",
      "Updating files:  42% (865/2058)\n",
      "Updating files:  43% (885/2058)\n",
      "Updating files:  44% (906/2058)\n",
      "Updating files:  45% (927/2058)\n",
      "Updating files:  46% (947/2058)\n",
      "Updating files:  47% (968/2058)\n",
      "Updating files:  48% (988/2058)\n",
      "Updating files:  49% (1009/2058)\n",
      "Updating files:  50% (1029/2058)\n",
      "Updating files:  51% (1050/2058)\n",
      "Updating files:  52% (1071/2058)\n",
      "Updating files:  53% (1091/2058)\n",
      "Updating files:  54% (1112/2058)\n",
      "Updating files:  55% (1132/2058)\n",
      "Updating files:  56% (1153/2058)\n",
      "Updating files:  57% (1174/2058)\n",
      "Updating files:  58% (1194/2058)\n",
      "Updating files:  59% (1215/2058)\n",
      "Updating files:  60% (1235/2058)\n",
      "Updating files:  61% (1256/2058)\n",
      "Updating files:  62% (1276/2058)\n",
      "Updating files:  63% (1297/2058)\n",
      "Updating files:  64% (1318/2058)\n",
      "Updating files:  65% (1338/2058)\n",
      "Updating files:  66% (1359/2058)\n",
      "Updating files:  67% (1379/2058)\n",
      "Updating files:  68% (1400/2058)\n",
      "Updating files:  69% (1421/2058)\n",
      "Updating files:  70% (1441/2058)\n",
      "Updating files:  70% (1461/2058)\n",
      "Updating files:  71% (1462/2058)\n",
      "Updating files:  72% (1482/2058)\n",
      "Updating files:  73% (1503/2058)\n",
      "Updating files:  74% (1523/2058)\n",
      "Updating files:  75% (1544/2058)\n",
      "Updating files:  76% (1565/2058)\n",
      "Updating files:  77% (1585/2058)\n",
      "Updating files:  78% (1606/2058)\n",
      "Updating files:  79% (1626/2058)\n",
      "Updating files:  80% (1647/2058)\n",
      "Updating files:  81% (1667/2058)\n",
      "Updating files:  82% (1688/2058)\n",
      "Updating files:  83% (1709/2058)\n",
      "Updating files:  84% (1729/2058)\n",
      "Updating files:  85% (1750/2058)\n",
      "Updating files:  86% (1770/2058)\n",
      "Updating files:  87% (1791/2058)\n",
      "Updating files:  88% (1812/2058)\n",
      "Updating files:  89% (1832/2058)\n",
      "Updating files:  90% (1853/2058)\n",
      "Updating files:  91% (1873/2058)\n",
      "Updating files:  92% (1894/2058)\n",
      "Updating files:  93% (1914/2058)\n",
      "Updating files:  94% (1935/2058)\n",
      "Updating files:  95% (1956/2058)\n",
      "Updating files:  96% (1976/2058)\n",
      "Updating files:  97% (1997/2058)\n",
      "Updating files:  98% (2017/2058)\n",
      "Updating files:  99% (2038/2058)\n",
      "Updating files: 100% (2058/2058)\n",
      "Updating files: 100% (2058/2058), done.\n"
     ]
    }
   ],
   "source": [
    "!cd github & git clone https://github.com/Farama-Foundation/ViZDoom.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eafe4ddd-196c-450f-8a54-cbb588bbec6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "  Using cached gym-0.26.2.tar.gz (721 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from gym) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from gym) (3.0.0)\n",
      "Collecting gym_notices>=0.0.4 (from gym)\n",
      "  Using cached gym_notices-0.0.8-py3-none-any.whl.metadata (1.0 kB)\n",
      "Using cached gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml): started\n",
      "  Building wheel for gym (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827635 sha256=5fe3e4c6d75241f9a05799fc010d63f54b2a89873633975c05dccf63574d52d8\n",
      "  Stored in directory: c:\\users\\19096\\appdata\\local\\pip\\cache\\wheels\\95\\51\\6c\\9bb05ebbe7c5cb8171dfaa3611f32622ca4658d53f31c79077\n",
      "Successfully built gym\n",
      "Installing collected packages: gym_notices, gym\n",
      "Successfully installed gym-0.26.2 gym_notices-0.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53f59b7b-1fc4-44cc-860e-a2963e73958d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "   ---------------------------------------- 0.0/38.8 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 6.8/38.8 MB 46.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 18.1/38.8 MB 47.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.4/38.8 MB 52.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/38.8 MB 51.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.8/38.8 MB 45.7 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc80a64c-1bd7-4f45-a060-a87e09f1610d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\19096\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "18f96b5c-7f64-4981-920a-96eca2a2da68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\19096\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.20 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.5.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\19096\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\19096\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\19096\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.9.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\19096\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.10.0.84)\n",
      "Requirement already satisfied: pygame in c:\\users\\19096\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.6.1)\n",
      "Collecting tensorboard>=2.9.1 (from stable-baselines3[extra])\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\19096\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (5.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\19096\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.66.5)\n",
      "Requirement already satisfied: rich in c:\\users\\19096\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (13.7.1)\n",
      "Collecting ale-py>=0.9.0 (from stable-baselines3[extra])\n",
      "  Downloading ale_py-0.10.1-cp312-cp312-win_amd64.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\19096\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (10.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
      "Collecting absl-py>=0.4 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Downloading grpcio-1.68.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\19096\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\19096\\anaconda3\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\19096\\anaconda3\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\19096\\anaconda3\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2023.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.15.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\19096\\anaconda3\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.3)\n",
      "Downloading ale_py-0.10.1-cp312-cp312-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 9.0 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 2.1/5.5 MB 9.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 7.5 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading grpcio-1.68.0-cp312-cp312-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 2.6/4.4 MB 15.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.4/4.4 MB 11.5 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: tensorboard-data-server, grpcio, ale-py, absl-py, tensorboard\n",
      "Successfully installed absl-py-2.1.0 ale-py-0.10.1 grpcio-1.68.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4dc03d18-cf8e-40ea-818e-76d67ea0f905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\19096\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\19096\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\19096\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\19096\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\19096\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\19096\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "77333010-2de0-4148-8f9d-a6593aecf119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizdoom import *\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3e389fd9-49be-4264-a3e2-738a0ba0c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a92b6f39-758e-43db-9d04-465964fed079",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "410706f0-ca56-4457-9664-ac49e52c8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizDoomGym(Env):\n",
    "    def __init__(self, render=False):\n",
    "        super().__init__()\n",
    "        self.game = DoomGame()\n",
    "        self.game.load_config('github/VizDoom/scenarios/basic.cfg')\n",
    "\n",
    "        if render:\n",
    "            self.game.set_window_visible(True)\n",
    "        else:\n",
    "            self.game.set_window_visible(False)\n",
    "            \n",
    "        self.game.init()\n",
    "\n",
    "        #Sets up observation space(image of game) and action space\n",
    "        self.observation_space = Box(low=0, high=255, shape=(1, 100, 160), dtype = np.uint8)\n",
    "        self.action_space = Discrete(3)\n",
    "        \n",
    "    def step(self, action):\n",
    "        actions = np.identity(3, dtype=np.uint8)\n",
    "        reward = self.game.make_action(actions[action], 4)\n",
    "        terminated = self.game.is_episode_finished()\n",
    "        truncated = False\n",
    "        info = {}\n",
    "        \n",
    "        if not terminated:\n",
    "            state = self.game.get_state().screen_buffer\n",
    "            state = self.preprocess(state)\n",
    "        else:\n",
    "            state = np.zeros(self.observation_space.shape, dtype=np.uint)\n",
    "        \n",
    "        return state, reward, terminated, truncated, info\n",
    "        \n",
    "    def render(self):\n",
    "        pass\n",
    "            \n",
    "    def reset(self, seed =None, options = None):\n",
    "        if seed is not None:\n",
    "            self.game.set_seed(seed)\n",
    "\n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        observation = self.preprocess(state)\n",
    "        info = {}\n",
    "        return observation, info\n",
    "        \n",
    "    #Grayscale game frame and resize it \n",
    "    def preprocess(self, observation):\n",
    "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY)\n",
    "        resized  = cv2.resize(gray, (160, 100), interpolation=cv2.INTER_AREA)\n",
    "        state = np.reshape(resized, (1, 100, 160))\n",
    "        return state.astype(np.float32) / 255.0\n",
    "        \n",
    "    def close(self):\n",
    "        self.game.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "09277eb2-78b2-439e-8fd0-b43719b96706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(model, env, trials=5):\n",
    "    total_rewards = []\n",
    "    for episode in range(trials):\n",
    "        state, _ = env.reset()\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        while not done:\n",
    "            with torch.no_grad():\n",
    "                logits, _ = agent.get_action(state)\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                action = torch.argmax(probs, dim=-1).item()\n",
    "                next_state, reward, terminated, truncated, info = env.step(action)\n",
    "                state = torch.FloatTensor(next_state).unsqueeze(0)\n",
    "                total_reward += reward\n",
    "                done = terminated\n",
    "        total_rewards.append(total_reward)\n",
    "        print(f\"Episode {episode + 1} Reward: {total_reward}\")\n",
    "        average_reward = np.mean(total_rewards)\n",
    "        print(f\"Average Reward over {trials} episodes: {average_reward}\")\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f3e327c8-ea47-4409-b295-d4d5a9ea49b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOAgent(nn.Module):\n",
    "    def __init__(self, action_space):\n",
    "        super(PPOAgent, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            #based logic on stablebaselines\n",
    "            nn.Conv2d(1, 32, kernel_size=8, stride=4),  # Output: [32, 24, 39]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),  # Output: [64, 11, 18]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),  # Output: [64, 9, 16]\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 9 * 16, 512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.policy_head = nn.Linear(512, action_space.n)\n",
    "        self.value_head = nn.Linear(512, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        x = self.forward(state)\n",
    "        logits = self.policy_head(x)\n",
    "        value = self.value_head(x)\n",
    "        return logits, value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7e1f9b17-0c91-4005-8c26-3c9dc2f45f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class PPO:\n",
    "    def __init__(self, env, agent, run_name, epochs=10, clip_eps=0.2, gamma=0.99, lr=1e-4, batch_size=3000):\n",
    "        self.env = env\n",
    "        self.agent = agent\n",
    "        self.optimizer = optim.Adam(self.agent.parameters(), lr=lr)\n",
    "        self.epochs = epochs\n",
    "        self.clip_eps = clip_eps\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        \n",
    "        log_dir = os.path.join(\"ppo_logs\", run_name)\n",
    "        self.writer = SummaryWriter(log_dir)\n",
    "        self.global_step = 0  \n",
    "\n",
    "    def compute_returns(self, rewards, dones, gamma):\n",
    "        returns = []\n",
    "        R = 0\n",
    "        for step in reversed(range(len(rewards))):\n",
    "            if dones[step]:\n",
    "                R = 0  \n",
    "            R = rewards[step] + gamma * R\n",
    "            returns.insert(0, R)\n",
    "        return returns\n",
    "\n",
    "    def learn(self, total_timesteps):\n",
    "        state, _ = self.env.reset()\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        timesteps = 0\n",
    "        episode_rewards = []\n",
    "        episode_reward = 0\n",
    "        episode = 0\n",
    "\n",
    "        while timesteps < total_timesteps:\n",
    "            states = []\n",
    "            actions = []\n",
    "            log_probs = []\n",
    "            rewards = []\n",
    "            values = []\n",
    "            dones = []\n",
    "\n",
    "            for _ in range(self.batch_size):\n",
    "                logits, value = self.agent.get_action(state)\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                dist = torch.distributions.Categorical(probs)\n",
    "                action = dist.sample()\n",
    "                log_prob = dist.log_prob(action)\n",
    "\n",
    "                next_state, reward, terminated, truncated, _ = self.env.step(action.item())\n",
    "                next_state = torch.FloatTensor(next_state).unsqueeze(0)\n",
    "\n",
    "                states.append(state)\n",
    "                actions.append(action)\n",
    "                log_probs.append(log_prob.detach())\n",
    "                rewards.append(reward)\n",
    "                values.append(value.detach().item())\n",
    "                dones.append(terminated)\n",
    "\n",
    "                episode_reward += reward\n",
    "                self.global_step += 1  \n",
    "\n",
    "                if terminated:\n",
    "                    episode_rewards.append(episode_reward)\n",
    "                    print(f\"Episode {episode} Reward: {episode_reward}\")\n",
    "\n",
    "                    # Calculate and log average reward\n",
    "                    if len(episode_rewards) >= 10:\n",
    "                        average_reward = np.mean(episode_rewards[-10:])\n",
    "                    else:\n",
    "                        average_reward = np.mean(episode_rewards)\n",
    "                    self.writer.add_scalar(\"Average Reward\", average_reward, self.global_step)\n",
    "\n",
    "                    episode_reward = 0\n",
    "                    episode += 1\n",
    "                    state, _ = self.env.reset()\n",
    "                    state = torch.FloatTensor(state).unsqueeze(0)\n",
    "                else:\n",
    "                    state = next_state\n",
    "\n",
    "                timesteps += 1\n",
    "\n",
    "            returns = self.compute_returns(rewards, dones, self.gamma)\n",
    "\n",
    "            states = torch.cat(states)\n",
    "            actions = torch.tensor(actions).unsqueeze(-1)\n",
    "            log_probs = torch.stack(log_probs)\n",
    "            returns = torch.tensor(returns).unsqueeze(-1)\n",
    "            values = torch.tensor(values).unsqueeze(-1)\n",
    "\n",
    "            advantages = returns - values\n",
    "            advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "\n",
    "\n",
    "            policy_losses = []\n",
    "            value_losses = []\n",
    "            entropies = []\n",
    "\n",
    "            for _ in range(self.epochs):\n",
    "                logits, value = self.agent.get_action(states)\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                dist = torch.distributions.Categorical(probs)\n",
    "                new_log_probs = dist.log_prob(actions.squeeze(-1)).unsqueeze(-1)\n",
    "                entropy = dist.entropy().mean()\n",
    "\n",
    "                ratio = (new_log_probs - log_probs).exp()\n",
    "                surr1 = ratio * advantages\n",
    "                surr2 = torch.clamp(ratio, 1 - self.clip_eps, 1 + self.clip_eps) * advantages\n",
    "\n",
    "                policy_loss = -torch.min(surr1, surr2).mean()\n",
    "                value_loss = nn.SmoothL1Loss()(value, returns)\n",
    "                loss = policy_loss + 0.5 * value_loss - 0.03 * entropy\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "\n",
    "                policy_losses.append(policy_loss.item())\n",
    "                value_losses.append(value_loss.item())\n",
    "                entropies.append(entropy.item())\n",
    "\n",
    "\n",
    "            avg_policy_loss = np.mean(policy_losses)\n",
    "            avg_value_loss = np.mean(value_losses)\n",
    "            avg_entropy = np.mean(entropies)\n",
    "\n",
    "            self.writer.add_scalar(\"Policy Loss\", avg_policy_loss, self.global_step)\n",
    "            self.writer.add_scalar(\"Value Loss\", avg_value_loss, self.global_step)\n",
    "            self.writer.add_scalar(\"Entropy\", avg_entropy, self.global_step)\n",
    "\n",
    "\n",
    "            print(f\"Timesteps: {timesteps}, Policy Loss: {avg_policy_loss}, Value Loss: {avg_value_loss}, Entropy: {avg_entropy}\")\n",
    "\n",
    "\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c23b586d-a5a1-49bc-a3d1-c1339d98ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(PPOCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d2e50fdf-b7ad-4307-befd-fa8de03f5b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_file_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2c63cb50-f3e4-4829-af3f-50f193e45759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 Reward: 0.0\n",
      "Episode 1 Reward: -360.0\n",
      "Episode 2 Reward: 91.0\n",
      "Episode 3 Reward: -365.0\n",
      "Episode 4 Reward: 75.0\n",
      "Episode 5 Reward: 68.0\n",
      "Episode 6 Reward: 51.0\n",
      "Episode 7 Reward: -173.0\n",
      "Episode 8 Reward: 75.0\n",
      "Episode 9 Reward: 95.0\n",
      "Episode 10 Reward: 87.0\n",
      "Episode 11 Reward: 79.0\n",
      "Episode 12 Reward: 87.0\n",
      "Episode 13 Reward: -370.0\n",
      "Episode 14 Reward: 87.0\n",
      "Episode 15 Reward: 95.0\n",
      "Episode 16 Reward: 87.0\n",
      "Episode 17 Reward: -370.0\n",
      "Episode 18 Reward: 68.0\n",
      "Episode 19 Reward: 87.0\n",
      "Episode 20 Reward: -380.0\n",
      "Episode 21 Reward: 95.0\n",
      "Episode 22 Reward: 95.0\n",
      "Episode 23 Reward: 35.0\n",
      "Episode 24 Reward: 87.0\n",
      "Episode 25 Reward: 13.0\n",
      "Episode 26 Reward: 95.0\n",
      "Episode 27 Reward: 95.0\n",
      "Episode 28 Reward: -370.0\n",
      "Episode 29 Reward: -375.0\n",
      "Episode 30 Reward: -12.0\n",
      "Episode 31 Reward: 42.0\n",
      "Episode 32 Reward: 33.0\n",
      "Episode 33 Reward: -50.0\n",
      "Episode 34 Reward: -355.0\n",
      "Episode 35 Reward: 79.0\n",
      "Episode 36 Reward: 37.0\n",
      "Episode 37 Reward: -365.0\n",
      "Episode 38 Reward: 29.0\n",
      "Episode 39 Reward: -84.0\n",
      "Episode 40 Reward: -77.0\n",
      "Episode 41 Reward: 95.0\n",
      "Episode 42 Reward: 95.0\n",
      "Episode 43 Reward: 72.0\n",
      "Episode 44 Reward: -380.0\n",
      "Episode 45 Reward: 39.0\n",
      "Episode 46 Reward: 87.0\n",
      "Episode 47 Reward: 87.0\n",
      "Episode 48 Reward: -183.0\n",
      "Episode 49 Reward: 71.0\n",
      "Episode 50 Reward: -100.0\n",
      "Episode 51 Reward: -365.0\n",
      "Episode 52 Reward: 25.0\n",
      "Episode 53 Reward: -125.0\n",
      "Episode 54 Reward: -119.0\n",
      "Episode 55 Reward: -385.0\n",
      "Episode 56 Reward: 79.0\n",
      "Episode 57 Reward: 91.0\n",
      "Episode 58 Reward: -187.0\n",
      "Episode 59 Reward: 95.0\n",
      "Episode 60 Reward: 28.0\n",
      "Episode 61 Reward: 95.0\n",
      "Episode 62 Reward: -375.0\n",
      "Episode 63 Reward: -370.0\n",
      "Episode 64 Reward: -355.0\n",
      "Episode 65 Reward: 62.0\n",
      "Episode 66 Reward: -193.0\n",
      "Episode 67 Reward: -385.0\n",
      "Episode 68 Reward: 95.0\n",
      "Episode 69 Reward: 21.0\n",
      "Episode 70 Reward: 95.0\n",
      "Episode 71 Reward: -141.0\n",
      "Episode 72 Reward: 91.0\n",
      "Episode 73 Reward: -380.0\n",
      "Episode 74 Reward: -360.0\n",
      "Episode 75 Reward: 91.0\n",
      "Episode 76 Reward: -380.0\n",
      "Episode 77 Reward: -375.0\n",
      "Episode 78 Reward: -375.0\n",
      "Episode 79 Reward: 87.0\n",
      "Episode 80 Reward: -360.0\n",
      "Episode 81 Reward: -77.0\n",
      "Episode 82 Reward: -360.0\n",
      "Episode 83 Reward: -375.0\n",
      "Episode 84 Reward: 25.0\n",
      "Episode 85 Reward: -29.0\n",
      "Episode 86 Reward: 1.0\n",
      "Episode 87 Reward: 72.0\n",
      "Episode 88 Reward: -375.0\n",
      "Episode 89 Reward: -240.0\n",
      "Episode 90 Reward: -173.0\n",
      "Episode 91 Reward: 95.0\n",
      "Timesteps: 3000, Policy Loss: -0.0014930334908499709, Value Loss: 117.10388412475587, Entropy: 1.09734708070755\n",
      "Episode 92 Reward: -36.0\n",
      "Episode 93 Reward: -355.0\n",
      "Episode 94 Reward: -46.0\n",
      "Episode 95 Reward: 56.0\n",
      "Episode 96 Reward: 95.0\n",
      "Episode 97 Reward: 95.0\n",
      "Episode 98 Reward: 95.0\n",
      "Episode 99 Reward: 95.0\n",
      "Episode 100 Reward: -189.0\n",
      "Episode 101 Reward: 37.0\n",
      "Episode 102 Reward: 95.0\n",
      "Episode 103 Reward: 91.0\n",
      "Episode 104 Reward: -100.0\n",
      "Episode 105 Reward: 95.0\n",
      "Episode 106 Reward: -360.0\n",
      "Episode 107 Reward: 87.0\n",
      "Episode 108 Reward: -129.0\n",
      "Episode 109 Reward: -380.0\n",
      "Episode 110 Reward: 95.0\n",
      "Episode 111 Reward: 95.0\n",
      "Episode 112 Reward: 43.0\n",
      "Episode 113 Reward: -245.0\n",
      "Episode 114 Reward: 87.0\n",
      "Episode 115 Reward: 95.0\n",
      "Episode 116 Reward: 91.0\n",
      "Episode 117 Reward: 95.0\n",
      "Episode 118 Reward: 91.0\n",
      "Episode 119 Reward: 29.0\n",
      "Episode 120 Reward: 67.0\n",
      "Episode 121 Reward: 79.0\n",
      "Episode 122 Reward: -20.0\n",
      "Episode 123 Reward: -365.0\n",
      "Episode 124 Reward: 75.0\n",
      "Episode 125 Reward: 91.0\n",
      "Episode 126 Reward: 50.0\n",
      "Episode 127 Reward: -5.0\n",
      "Episode 128 Reward: 35.0\n",
      "Episode 129 Reward: -18.0\n",
      "Episode 130 Reward: 87.0\n",
      "Episode 131 Reward: 29.0\n",
      "Episode 132 Reward: -89.0\n",
      "Episode 133 Reward: -380.0\n",
      "Episode 134 Reward: -380.0\n",
      "Episode 135 Reward: -134.0\n",
      "Episode 136 Reward: 71.0\n",
      "Episode 137 Reward: -151.0\n",
      "Episode 138 Reward: 72.0\n",
      "Episode 139 Reward: -258.0\n",
      "Episode 140 Reward: 95.0\n",
      "Episode 141 Reward: -360.0\n",
      "Episode 142 Reward: 95.0\n",
      "Episode 143 Reward: -100.0\n",
      "Episode 144 Reward: -4.0\n",
      "Episode 145 Reward: 41.0\n",
      "Episode 146 Reward: -385.0\n",
      "Episode 147 Reward: -380.0\n",
      "Episode 148 Reward: 45.0\n",
      "Episode 149 Reward: -16.0\n",
      "Episode 150 Reward: 95.0\n",
      "Episode 151 Reward: -380.0\n",
      "Episode 152 Reward: -380.0\n",
      "Episode 153 Reward: 95.0\n",
      "Episode 154 Reward: 87.0\n",
      "Episode 155 Reward: 21.0\n",
      "Episode 156 Reward: -200.0\n",
      "Episode 157 Reward: 91.0\n",
      "Episode 158 Reward: -375.0\n",
      "Episode 159 Reward: 62.0\n",
      "Episode 160 Reward: 95.0\n",
      "Episode 161 Reward: 54.0\n",
      "Episode 162 Reward: -370.0\n",
      "Episode 163 Reward: 71.0\n",
      "Episode 164 Reward: 83.0\n",
      "Episode 165 Reward: -21.0\n",
      "Episode 166 Reward: -91.0\n",
      "Episode 167 Reward: 87.0\n",
      "Episode 168 Reward: 87.0\n",
      "Episode 169 Reward: 41.0\n",
      "Episode 170 Reward: 91.0\n",
      "Episode 171 Reward: -370.0\n",
      "Episode 172 Reward: 91.0\n",
      "Episode 173 Reward: 95.0\n",
      "Episode 174 Reward: -385.0\n",
      "Episode 175 Reward: -186.0\n",
      "Episode 176 Reward: 95.0\n",
      "Episode 177 Reward: 72.0\n",
      "Episode 178 Reward: -141.0\n",
      "Episode 179 Reward: 95.0\n",
      "Episode 180 Reward: -380.0\n",
      "Episode 181 Reward: -380.0\n",
      "Episode 182 Reward: -365.0\n",
      "Episode 183 Reward: 87.0\n",
      "Episode 184 Reward: 91.0\n",
      "Episode 185 Reward: -375.0\n",
      "Episode 186 Reward: -153.0\n",
      "Episode 187 Reward: 95.0\n",
      "Episode 188 Reward: -233.0\n",
      "Episode 189 Reward: -96.0\n",
      "Episode 190 Reward: 83.0\n",
      "Episode 191 Reward: 87.0\n",
      "Episode 192 Reward: 95.0\n",
      "Episode 193 Reward: 9.0\n",
      "Episode 194 Reward: -375.0\n",
      "Episode 195 Reward: 95.0\n",
      "Episode 196 Reward: 95.0\n",
      "Episode 197 Reward: -375.0\n",
      "Episode 198 Reward: -73.0\n",
      "Episode 199 Reward: 95.0\n",
      "Episode 200 Reward: 95.0\n",
      "Timesteps: 6000, Policy Loss: 0.004236593396883847, Value Loss: 108.79021453857422, Entropy: 1.0664230465888977\n",
      "Episode 201 Reward: -21.0\n",
      "Episode 202 Reward: 14.0\n",
      "Episode 203 Reward: 30.0\n",
      "Episode 204 Reward: 91.0\n",
      "Episode 205 Reward: -365.0\n",
      "Episode 206 Reward: 95.0\n",
      "Episode 207 Reward: -370.0\n",
      "Episode 208 Reward: -1.0\n",
      "Episode 209 Reward: -375.0\n",
      "Episode 210 Reward: 46.0\n",
      "Episode 211 Reward: 95.0\n",
      "Episode 212 Reward: 21.0\n",
      "Episode 213 Reward: -375.0\n",
      "Episode 214 Reward: 95.0\n",
      "Episode 215 Reward: 3.0\n",
      "Episode 216 Reward: -142.0\n",
      "Episode 217 Reward: 87.0\n",
      "Episode 218 Reward: -380.0\n",
      "Episode 219 Reward: -58.0\n",
      "Episode 220 Reward: 95.0\n",
      "Episode 221 Reward: 95.0\n",
      "Episode 222 Reward: 95.0\n",
      "Episode 223 Reward: 67.0\n",
      "Episode 224 Reward: -375.0\n",
      "Episode 225 Reward: -184.0\n",
      "Episode 226 Reward: 95.0\n",
      "Episode 227 Reward: 87.0\n",
      "Episode 228 Reward: -370.0\n",
      "Episode 229 Reward: 71.0\n",
      "Episode 230 Reward: 95.0\n",
      "Episode 231 Reward: -380.0\n",
      "Episode 232 Reward: 95.0\n",
      "Episode 233 Reward: 79.0\n",
      "Episode 234 Reward: -39.0\n",
      "Episode 235 Reward: 95.0\n",
      "Episode 236 Reward: 91.0\n",
      "Episode 237 Reward: -380.0\n",
      "Episode 238 Reward: 95.0\n",
      "Episode 239 Reward: -365.0\n",
      "Episode 240 Reward: 58.0\n",
      "Episode 241 Reward: 95.0\n",
      "Episode 242 Reward: -370.0\n",
      "Episode 243 Reward: 70.0\n",
      "Episode 244 Reward: -160.0\n",
      "Episode 245 Reward: 95.0\n",
      "Episode 246 Reward: -89.0\n",
      "Episode 247 Reward: -375.0\n",
      "Episode 248 Reward: 91.0\n",
      "Episode 249 Reward: -86.0\n",
      "Episode 250 Reward: -370.0\n",
      "Episode 251 Reward: 95.0\n",
      "Episode 252 Reward: 50.0\n",
      "Episode 253 Reward: -375.0\n",
      "Episode 254 Reward: -345.0\n",
      "Episode 255 Reward: 21.0\n",
      "Episode 256 Reward: 95.0\n",
      "Episode 257 Reward: 56.0\n",
      "Episode 258 Reward: 91.0\n",
      "Episode 259 Reward: 62.0\n",
      "Episode 260 Reward: -375.0\n",
      "Episode 261 Reward: 68.0\n",
      "Episode 262 Reward: 72.0\n",
      "Episode 263 Reward: 95.0\n",
      "Episode 264 Reward: 95.0\n",
      "Episode 265 Reward: -365.0\n",
      "Episode 266 Reward: -370.0\n",
      "Episode 267 Reward: 71.0\n",
      "Episode 268 Reward: -226.0\n",
      "Episode 269 Reward: 95.0\n",
      "Episode 270 Reward: -365.0\n",
      "Episode 271 Reward: 95.0\n",
      "Episode 272 Reward: -380.0\n",
      "Episode 273 Reward: 87.0\n",
      "Episode 274 Reward: 42.0\n",
      "Episode 275 Reward: -236.0\n",
      "Episode 276 Reward: 56.0\n",
      "Episode 277 Reward: -207.0\n",
      "Episode 278 Reward: -95.0\n",
      "Episode 279 Reward: -163.0\n",
      "Episode 280 Reward: 95.0\n",
      "Episode 281 Reward: 95.0\n",
      "Episode 282 Reward: 83.0\n",
      "Episode 283 Reward: 95.0\n",
      "Episode 284 Reward: 91.0\n",
      "Episode 285 Reward: 95.0\n",
      "Episode 286 Reward: -80.0\n",
      "Episode 287 Reward: 33.0\n",
      "Episode 288 Reward: 67.0\n",
      "Episode 289 Reward: -365.0\n",
      "Episode 290 Reward: -375.0\n",
      "Episode 291 Reward: 83.0\n",
      "Episode 292 Reward: -34.0\n",
      "Episode 293 Reward: -390.0\n",
      "Episode 294 Reward: -380.0\n",
      "Episode 295 Reward: 87.0\n",
      "Episode 296 Reward: -375.0\n",
      "Episode 297 Reward: 95.0\n",
      "Episode 298 Reward: -365.0\n",
      "Episode 299 Reward: 87.0\n",
      "Episode 300 Reward: 95.0\n",
      "Timesteps: 9000, Policy Loss: -0.0024369180089635735, Value Loss: 112.92356719970704, Entropy: 1.0589475154876709\n",
      "Episode 301 Reward: -62.0\n",
      "Episode 302 Reward: -380.0\n",
      "Episode 303 Reward: 95.0\n",
      "Episode 304 Reward: -19.0\n",
      "Episode 305 Reward: 55.0\n",
      "Episode 306 Reward: 87.0\n",
      "Episode 307 Reward: 95.0\n",
      "Episode 308 Reward: 87.0\n",
      "Episode 309 Reward: -370.0\n",
      "Episode 310 Reward: 95.0\n",
      "Episode 311 Reward: 95.0\n",
      "Episode 312 Reward: -30.0\n",
      "Episode 313 Reward: -375.0\n",
      "Episode 314 Reward: 2.0\n",
      "Episode 315 Reward: 87.0\n",
      "Episode 316 Reward: -370.0\n",
      "Episode 317 Reward: 95.0\n",
      "Episode 318 Reward: -380.0\n",
      "Episode 319 Reward: -385.0\n",
      "Episode 320 Reward: 51.0\n",
      "Episode 321 Reward: -380.0\n",
      "Episode 322 Reward: 95.0\n",
      "Episode 323 Reward: -385.0\n",
      "Episode 324 Reward: -375.0\n",
      "Episode 325 Reward: -385.0\n",
      "Episode 326 Reward: 47.0\n",
      "Episode 327 Reward: -375.0\n",
      "Episode 328 Reward: 95.0\n",
      "Episode 329 Reward: 10.0\n",
      "Episode 330 Reward: 95.0\n",
      "Episode 331 Reward: -65.0\n",
      "Episode 332 Reward: 95.0\n",
      "Episode 333 Reward: 95.0\n",
      "Episode 334 Reward: -375.0\n",
      "Episode 335 Reward: 95.0\n",
      "Episode 336 Reward: 16.0\n",
      "Episode 337 Reward: 67.0\n",
      "Episode 338 Reward: 95.0\n",
      "Episode 339 Reward: 51.0\n",
      "Episode 340 Reward: 24.0\n",
      "Episode 341 Reward: 91.0\n",
      "Episode 342 Reward: 72.0\n",
      "Episode 343 Reward: -375.0\n",
      "Episode 344 Reward: 95.0\n",
      "Episode 345 Reward: 95.0\n",
      "Episode 346 Reward: 10.0\n",
      "Episode 347 Reward: -365.0\n",
      "Episode 348 Reward: 95.0\n",
      "Episode 349 Reward: 52.0\n",
      "Episode 350 Reward: 55.0\n",
      "Episode 351 Reward: 95.0\n",
      "Episode 352 Reward: -380.0\n",
      "Episode 353 Reward: 87.0\n",
      "Episode 354 Reward: 95.0\n",
      "Episode 355 Reward: 87.0\n",
      "Episode 356 Reward: -390.0\n",
      "Episode 357 Reward: -380.0\n",
      "Episode 358 Reward: 83.0\n",
      "Episode 359 Reward: -56.0\n",
      "Episode 360 Reward: 95.0\n",
      "Episode 361 Reward: 91.0\n",
      "Episode 362 Reward: -365.0\n",
      "Episode 363 Reward: 95.0\n",
      "Episode 364 Reward: -208.0\n",
      "Episode 365 Reward: 95.0\n",
      "Episode 366 Reward: -375.0\n",
      "Episode 367 Reward: 95.0\n",
      "Episode 368 Reward: 46.0\n",
      "Episode 369 Reward: 83.0\n",
      "Episode 370 Reward: -120.0\n",
      "Episode 371 Reward: 95.0\n",
      "Episode 372 Reward: -211.0\n",
      "Episode 373 Reward: 91.0\n",
      "Episode 374 Reward: 68.0\n",
      "Episode 375 Reward: -21.0\n",
      "Episode 376 Reward: 95.0\n",
      "Episode 377 Reward: -60.0\n",
      "Episode 378 Reward: 95.0\n",
      "Episode 379 Reward: 95.0\n",
      "Episode 380 Reward: -55.0\n",
      "Episode 381 Reward: -9.0\n",
      "Episode 382 Reward: 16.0\n",
      "Episode 383 Reward: -375.0\n",
      "Episode 384 Reward: -9.0\n",
      "Episode 385 Reward: -390.0\n",
      "Episode 386 Reward: 95.0\n",
      "Episode 387 Reward: 95.0\n",
      "Episode 388 Reward: -41.0\n",
      "Episode 389 Reward: -375.0\n",
      "Episode 390 Reward: 91.0\n",
      "Episode 391 Reward: 67.0\n",
      "Episode 392 Reward: -29.0\n",
      "Episode 393 Reward: 95.0\n",
      "Episode 394 Reward: -375.0\n",
      "Episode 395 Reward: -66.0\n",
      "Episode 396 Reward: 95.0\n",
      "Episode 397 Reward: -370.0\n",
      "Episode 398 Reward: -375.0\n",
      "Episode 399 Reward: 58.0\n",
      "Episode 400 Reward: -370.0\n",
      "Episode 401 Reward: 83.0\n",
      "Episode 402 Reward: 95.0\n",
      "Episode 403 Reward: 87.0\n",
      "Episode 404 Reward: 95.0\n",
      "Episode 405 Reward: 91.0\n",
      "Episode 406 Reward: 95.0\n",
      "Episode 407 Reward: -375.0\n",
      "Episode 408 Reward: 87.0\n",
      "Episode 409 Reward: 95.0\n",
      "Episode 410 Reward: -375.0\n",
      "Episode 411 Reward: 95.0\n",
      "Episode 412 Reward: 91.0\n",
      "Episode 413 Reward: 87.0\n",
      "Episode 414 Reward: 83.0\n",
      "Timesteps: 12000, Policy Loss: 0.004266024774782551, Value Loss: 103.97489013671876, Entropy: 1.0429250001907349\n",
      "Episode 415 Reward: -380.0\n",
      "Episode 416 Reward: -365.0\n",
      "Episode 417 Reward: 95.0\n",
      "Episode 418 Reward: 55.0\n",
      "Episode 419 Reward: 95.0\n",
      "Episode 420 Reward: 75.0\n",
      "Episode 421 Reward: 87.0\n",
      "Episode 422 Reward: 59.0\n",
      "Episode 423 Reward: 29.0\n",
      "Episode 424 Reward: -370.0\n",
      "Episode 425 Reward: 95.0\n",
      "Episode 426 Reward: -365.0\n",
      "Episode 427 Reward: 95.0\n",
      "Episode 428 Reward: 95.0\n",
      "Episode 429 Reward: -365.0\n",
      "Episode 430 Reward: -365.0\n",
      "Episode 431 Reward: -365.0\n",
      "Episode 432 Reward: 55.0\n",
      "Episode 433 Reward: -360.0\n",
      "Episode 434 Reward: -345.0\n",
      "Episode 435 Reward: 91.0\n",
      "Episode 436 Reward: 91.0\n",
      "Episode 437 Reward: 95.0\n",
      "Episode 438 Reward: 87.0\n",
      "Episode 439 Reward: -365.0\n",
      "Episode 440 Reward: -370.0\n",
      "Episode 441 Reward: 95.0\n",
      "Episode 442 Reward: -375.0\n",
      "Episode 443 Reward: -355.0\n",
      "Episode 444 Reward: 91.0\n",
      "Episode 445 Reward: 58.0\n",
      "Episode 446 Reward: 91.0\n",
      "Episode 447 Reward: 28.0\n",
      "Episode 448 Reward: 91.0\n",
      "Episode 449 Reward: -370.0\n",
      "Episode 450 Reward: -365.0\n",
      "Episode 451 Reward: 91.0\n",
      "Episode 452 Reward: 95.0\n",
      "Episode 453 Reward: 79.0\n",
      "Episode 454 Reward: 91.0\n",
      "Episode 455 Reward: -365.0\n",
      "Episode 456 Reward: 83.0\n",
      "Episode 457 Reward: 91.0\n",
      "Episode 458 Reward: 67.0\n",
      "Episode 459 Reward: -380.0\n",
      "Episode 460 Reward: 95.0\n",
      "Episode 461 Reward: 95.0\n",
      "Episode 462 Reward: 0.0\n",
      "Episode 463 Reward: 26.0\n",
      "Episode 464 Reward: 91.0\n",
      "Episode 465 Reward: -360.0\n",
      "Episode 466 Reward: 95.0\n",
      "Episode 467 Reward: -370.0\n",
      "Episode 468 Reward: -370.0\n",
      "Episode 469 Reward: -355.0\n",
      "Episode 470 Reward: -365.0\n",
      "Episode 471 Reward: 91.0\n",
      "Episode 472 Reward: 29.0\n",
      "Episode 473 Reward: -365.0\n",
      "Episode 474 Reward: 91.0\n",
      "Episode 475 Reward: 9.0\n",
      "Episode 476 Reward: -365.0\n",
      "Episode 477 Reward: 95.0\n",
      "Episode 478 Reward: 51.0\n",
      "Episode 479 Reward: 95.0\n",
      "Episode 480 Reward: -370.0\n",
      "Episode 481 Reward: -370.0\n",
      "Episode 482 Reward: -360.0\n",
      "Episode 483 Reward: -380.0\n",
      "Episode 484 Reward: -370.0\n",
      "Episode 485 Reward: -365.0\n",
      "Episode 486 Reward: 16.0\n",
      "Episode 487 Reward: -355.0\n",
      "Episode 488 Reward: 91.0\n",
      "Episode 489 Reward: 28.0\n",
      "Episode 490 Reward: -370.0\n",
      "Episode 491 Reward: -365.0\n",
      "Episode 492 Reward: -350.0\n",
      "Episode 493 Reward: -355.0\n",
      "Episode 494 Reward: -360.0\n",
      "Timesteps: 15000, Policy Loss: 0.03478252870620544, Value Loss: 80.9123146057129, Entropy: 0.9218179643154144\n",
      "Episode 495 Reward: -365.0\n",
      "Episode 496 Reward: 91.0\n",
      "Episode 497 Reward: 91.0\n",
      "Episode 498 Reward: 87.0\n",
      "Episode 499 Reward: 95.0\n",
      "Episode 500 Reward: 95.0\n",
      "Episode 501 Reward: 87.0\n",
      "Episode 502 Reward: 95.0\n",
      "Episode 503 Reward: 68.0\n",
      "Episode 504 Reward: 95.0\n",
      "Episode 505 Reward: -370.0\n",
      "Episode 506 Reward: -360.0\n",
      "Episode 507 Reward: 95.0\n",
      "Episode 508 Reward: -355.0\n",
      "Episode 509 Reward: 91.0\n",
      "Episode 510 Reward: -375.0\n",
      "Episode 511 Reward: -375.0\n",
      "Episode 512 Reward: 60.0\n",
      "Episode 513 Reward: -375.0\n",
      "Episode 514 Reward: 83.0\n",
      "Episode 515 Reward: 95.0\n",
      "Episode 516 Reward: -370.0\n",
      "Episode 517 Reward: -375.0\n",
      "Episode 518 Reward: 87.0\n",
      "Episode 519 Reward: 87.0\n",
      "Episode 520 Reward: 67.0\n",
      "Episode 521 Reward: 63.0\n",
      "Episode 522 Reward: -375.0\n",
      "Episode 523 Reward: -370.0\n",
      "Episode 524 Reward: -370.0\n",
      "Episode 525 Reward: -370.0\n",
      "Episode 526 Reward: 95.0\n",
      "Episode 527 Reward: -370.0\n",
      "Episode 528 Reward: -365.0\n",
      "Episode 529 Reward: 87.0\n",
      "Episode 530 Reward: -380.0\n",
      "Episode 531 Reward: -370.0\n",
      "Episode 532 Reward: -365.0\n",
      "Episode 533 Reward: 68.0\n",
      "Episode 534 Reward: 91.0\n",
      "Episode 535 Reward: 91.0\n",
      "Episode 536 Reward: 95.0\n",
      "Episode 537 Reward: 95.0\n",
      "Episode 538 Reward: 43.0\n",
      "Episode 539 Reward: 87.0\n",
      "Episode 540 Reward: 28.0\n",
      "Episode 541 Reward: 87.0\n",
      "Episode 542 Reward: 91.0\n",
      "Episode 543 Reward: -380.0\n",
      "Episode 544 Reward: -370.0\n",
      "Episode 545 Reward: 95.0\n",
      "Episode 546 Reward: -370.0\n",
      "Episode 547 Reward: -375.0\n",
      "Episode 548 Reward: 58.0\n",
      "Episode 549 Reward: -78.0\n",
      "Episode 550 Reward: -370.0\n",
      "Episode 551 Reward: -380.0\n",
      "Episode 552 Reward: -375.0\n",
      "Episode 553 Reward: -385.0\n",
      "Episode 554 Reward: 91.0\n",
      "Episode 555 Reward: -370.0\n",
      "Episode 556 Reward: -26.0\n",
      "Episode 557 Reward: -370.0\n",
      "Episode 558 Reward: 70.0\n",
      "Episode 559 Reward: -370.0\n",
      "Episode 560 Reward: -370.0\n",
      "Episode 561 Reward: -380.0\n",
      "Episode 562 Reward: -360.0\n",
      "Episode 563 Reward: 91.0\n",
      "Episode 564 Reward: 91.0\n",
      "Episode 565 Reward: 91.0\n",
      "Episode 566 Reward: -375.0\n",
      "Episode 567 Reward: -350.0\n",
      "Episode 568 Reward: -370.0\n",
      "Episode 569 Reward: 95.0\n",
      "Episode 570 Reward: 95.0\n",
      "Episode 571 Reward: -370.0\n",
      "Episode 572 Reward: 95.0\n",
      "Episode 573 Reward: 45.0\n",
      "Episode 574 Reward: 91.0\n",
      "Episode 575 Reward: 28.0\n",
      "Episode 576 Reward: 91.0\n",
      "Episode 577 Reward: 76.0\n",
      "Timesteps: 18000, Policy Loss: 0.0385190562700231, Value Loss: 78.41521530151367, Entropy: 0.7247389674186706\n",
      "Episode 578 Reward: -380.0\n",
      "Episode 579 Reward: -385.0\n",
      "Episode 580 Reward: 95.0\n",
      "Episode 581 Reward: -390.0\n",
      "Episode 582 Reward: 95.0\n",
      "Episode 583 Reward: 91.0\n",
      "Episode 584 Reward: 95.0\n",
      "Episode 585 Reward: 95.0\n",
      "Episode 586 Reward: 95.0\n",
      "Episode 587 Reward: -256.0\n",
      "Episode 588 Reward: 95.0\n",
      "Episode 589 Reward: 87.0\n",
      "Episode 590 Reward: -390.0\n",
      "Episode 591 Reward: 91.0\n",
      "Episode 592 Reward: 95.0\n",
      "Episode 593 Reward: -380.0\n",
      "Episode 594 Reward: -375.0\n",
      "Episode 595 Reward: -385.0\n",
      "Episode 596 Reward: 95.0\n",
      "Episode 597 Reward: 95.0\n",
      "Episode 598 Reward: 91.0\n",
      "Episode 599 Reward: 76.0\n",
      "Episode 600 Reward: 95.0\n",
      "Episode 601 Reward: 52.0\n",
      "Episode 602 Reward: 91.0\n",
      "Episode 603 Reward: -375.0\n",
      "Episode 604 Reward: 52.0\n",
      "Episode 605 Reward: 95.0\n",
      "Episode 606 Reward: -380.0\n",
      "Episode 607 Reward: 95.0\n",
      "Episode 608 Reward: 95.0\n",
      "Episode 609 Reward: 95.0\n",
      "Episode 610 Reward: 91.0\n",
      "Episode 611 Reward: 95.0\n",
      "Episode 612 Reward: 91.0\n",
      "Episode 613 Reward: 95.0\n",
      "Episode 614 Reward: 91.0\n",
      "Episode 615 Reward: 87.0\n",
      "Episode 616 Reward: -385.0\n",
      "Episode 617 Reward: -370.0\n",
      "Episode 618 Reward: 95.0\n",
      "Episode 619 Reward: 79.0\n",
      "Episode 620 Reward: 47.0\n",
      "Episode 621 Reward: 95.0\n",
      "Episode 622 Reward: 17.0\n",
      "Episode 623 Reward: -385.0\n",
      "Episode 624 Reward: 49.0\n",
      "Episode 625 Reward: -45.0\n",
      "Episode 626 Reward: -385.0\n",
      "Episode 627 Reward: -400.0\n",
      "Episode 628 Reward: -390.0\n",
      "Episode 629 Reward: 91.0\n",
      "Episode 630 Reward: 87.0\n",
      "Episode 631 Reward: -385.0\n",
      "Episode 632 Reward: 91.0\n",
      "Episode 633 Reward: 95.0\n",
      "Episode 634 Reward: 95.0\n",
      "Episode 635 Reward: -385.0\n",
      "Episode 636 Reward: 91.0\n",
      "Episode 637 Reward: 91.0\n",
      "Episode 638 Reward: 95.0\n",
      "Episode 639 Reward: -380.0\n",
      "Episode 640 Reward: 91.0\n",
      "Episode 641 Reward: -390.0\n",
      "Episode 642 Reward: -365.0\n",
      "Episode 643 Reward: -390.0\n",
      "Episode 644 Reward: 59.0\n",
      "Episode 645 Reward: 91.0\n",
      "Episode 646 Reward: 75.0\n",
      "Episode 647 Reward: 95.0\n",
      "Episode 648 Reward: 87.0\n",
      "Episode 649 Reward: -385.0\n",
      "Episode 650 Reward: -385.0\n",
      "Episode 651 Reward: 95.0\n",
      "Episode 652 Reward: 95.0\n",
      "Episode 653 Reward: 95.0\n",
      "Episode 654 Reward: 95.0\n",
      "Episode 655 Reward: -375.0\n",
      "Episode 656 Reward: 95.0\n",
      "Episode 657 Reward: 91.0\n",
      "Episode 658 Reward: -380.0\n",
      "Episode 659 Reward: 95.0\n",
      "Episode 660 Reward: -385.0\n",
      "Episode 661 Reward: -375.0\n",
      "Episode 662 Reward: 91.0\n",
      "Episode 663 Reward: -385.0\n",
      "Episode 664 Reward: 91.0\n",
      "Episode 665 Reward: 71.0\n",
      "Episode 666 Reward: 91.0\n",
      "Episode 667 Reward: -375.0\n",
      "Episode 668 Reward: -385.0\n",
      "Episode 669 Reward: 49.0\n",
      "Episode 670 Reward: 52.0\n",
      "Episode 671 Reward: 95.0\n",
      "Episode 672 Reward: 91.0\n",
      "Episode 673 Reward: 87.0\n",
      "Episode 674 Reward: 95.0\n",
      "Episode 675 Reward: -385.0\n",
      "Episode 676 Reward: 83.0\n",
      "Episode 677 Reward: 95.0\n",
      "Episode 678 Reward: 87.0\n",
      "Episode 679 Reward: 95.0\n",
      "Episode 680 Reward: 95.0\n",
      "Episode 681 Reward: 95.0\n",
      "Episode 682 Reward: 91.0\n",
      "Episode 683 Reward: 95.0\n",
      "Episode 684 Reward: 95.0\n",
      "Episode 685 Reward: -385.0\n",
      "Episode 686 Reward: -89.0\n",
      "Episode 687 Reward: 95.0\n",
      "Episode 688 Reward: 91.0\n",
      "Episode 689 Reward: 95.0\n",
      "Episode 690 Reward: 95.0\n",
      "Episode 691 Reward: 34.0\n",
      "Episode 692 Reward: 53.0\n",
      "Episode 693 Reward: -390.0\n",
      "Episode 694 Reward: -385.0\n",
      "Episode 695 Reward: 72.0\n",
      "Episode 696 Reward: 91.0\n",
      "Episode 697 Reward: 95.0\n",
      "Episode 698 Reward: 95.0\n",
      "Episode 699 Reward: 83.0\n",
      "Episode 700 Reward: 91.0\n",
      "Episode 701 Reward: 95.0\n",
      "Episode 702 Reward: 57.0\n",
      "Episode 703 Reward: 95.0\n",
      "Episode 704 Reward: 95.0\n",
      "Episode 705 Reward: 95.0\n",
      "Episode 706 Reward: 95.0\n",
      "Timesteps: 21000, Policy Loss: 0.011657382502313851, Value Loss: 88.13865127563477, Entropy: 0.7695570051670074\n",
      "Episode 707 Reward: -375.0\n",
      "Episode 708 Reward: -370.0\n",
      "Episode 709 Reward: 91.0\n",
      "Episode 710 Reward: 72.0\n",
      "Episode 711 Reward: -390.0\n",
      "Episode 712 Reward: -375.0\n",
      "Episode 713 Reward: 9.0\n",
      "Episode 714 Reward: 91.0\n",
      "Episode 715 Reward: 91.0\n",
      "Episode 716 Reward: -385.0\n",
      "Episode 717 Reward: 91.0\n",
      "Episode 718 Reward: 95.0\n",
      "Episode 719 Reward: 95.0\n",
      "Episode 720 Reward: -9.0\n",
      "Episode 721 Reward: 95.0\n",
      "Episode 722 Reward: 3.0\n",
      "Episode 723 Reward: 87.0\n",
      "Episode 724 Reward: 91.0\n",
      "Episode 725 Reward: -390.0\n",
      "Episode 726 Reward: 95.0\n",
      "Episode 727 Reward: 75.0\n",
      "Episode 728 Reward: 91.0\n",
      "Episode 729 Reward: 91.0\n",
      "Episode 730 Reward: -390.0\n",
      "Episode 731 Reward: 95.0\n",
      "Episode 732 Reward: 95.0\n",
      "Episode 733 Reward: 95.0\n",
      "Episode 734 Reward: 95.0\n",
      "Episode 735 Reward: 95.0\n",
      "Episode 736 Reward: -370.0\n",
      "Episode 737 Reward: 95.0\n",
      "Episode 738 Reward: 71.0\n",
      "Episode 739 Reward: 95.0\n",
      "Episode 740 Reward: 95.0\n",
      "Episode 741 Reward: -370.0\n",
      "Episode 742 Reward: -390.0\n",
      "Episode 743 Reward: 70.0\n",
      "Episode 744 Reward: 87.0\n",
      "Episode 745 Reward: 95.0\n",
      "Episode 746 Reward: 95.0\n",
      "Episode 747 Reward: -375.0\n",
      "Episode 748 Reward: -385.0\n",
      "Episode 749 Reward: 95.0\n",
      "Episode 750 Reward: -380.0\n",
      "Episode 751 Reward: 95.0\n",
      "Episode 752 Reward: 47.0\n",
      "Episode 753 Reward: 91.0\n",
      "Episode 754 Reward: -390.0\n",
      "Episode 755 Reward: 95.0\n",
      "Episode 756 Reward: -385.0\n",
      "Episode 757 Reward: 95.0\n",
      "Episode 758 Reward: -370.0\n",
      "Episode 759 Reward: 95.0\n",
      "Episode 760 Reward: 95.0\n",
      "Episode 761 Reward: 87.0\n",
      "Episode 762 Reward: -380.0\n",
      "Episode 763 Reward: 95.0\n",
      "Episode 764 Reward: 95.0\n",
      "Episode 765 Reward: -385.0\n",
      "Episode 766 Reward: -370.0\n",
      "Episode 767 Reward: -380.0\n",
      "Episode 768 Reward: -375.0\n",
      "Episode 769 Reward: 87.0\n",
      "Episode 770 Reward: -385.0\n",
      "Episode 771 Reward: -385.0\n",
      "Episode 772 Reward: -385.0\n",
      "Episode 773 Reward: 95.0\n",
      "Episode 774 Reward: -385.0\n",
      "Episode 775 Reward: 67.0\n",
      "Episode 776 Reward: 95.0\n",
      "Episode 777 Reward: 95.0\n",
      "Episode 778 Reward: 95.0\n",
      "Episode 779 Reward: 33.0\n",
      "Episode 780 Reward: 95.0\n",
      "Episode 781 Reward: 91.0\n",
      "Episode 782 Reward: -380.0\n",
      "Episode 783 Reward: 91.0\n",
      "Episode 784 Reward: -1.0\n",
      "Episode 785 Reward: 95.0\n",
      "Episode 786 Reward: -370.0\n",
      "Episode 787 Reward: 91.0\n",
      "Episode 788 Reward: 91.0\n",
      "Episode 789 Reward: 95.0\n",
      "Episode 790 Reward: -380.0\n",
      "Episode 791 Reward: 91.0\n",
      "Episode 792 Reward: 87.0\n",
      "Episode 793 Reward: 95.0\n",
      "Episode 794 Reward: 95.0\n",
      "Episode 795 Reward: 41.0\n",
      "Episode 796 Reward: -380.0\n",
      "Episode 797 Reward: 95.0\n",
      "Episode 798 Reward: 91.0\n",
      "Episode 799 Reward: -380.0\n",
      "Episode 800 Reward: 95.0\n",
      "Episode 801 Reward: 91.0\n",
      "Episode 802 Reward: 42.0\n",
      "Episode 803 Reward: 95.0\n",
      "Episode 804 Reward: -380.0\n",
      "Episode 805 Reward: -385.0\n",
      "Episode 806 Reward: 29.0\n",
      "Episode 807 Reward: 91.0\n",
      "Episode 808 Reward: -375.0\n",
      "Episode 809 Reward: 95.0\n",
      "Episode 810 Reward: 63.0\n",
      "Episode 811 Reward: 91.0\n",
      "Episode 812 Reward: -385.0\n",
      "Episode 813 Reward: 95.0\n",
      "Episode 814 Reward: 95.0\n",
      "Episode 815 Reward: -380.0\n",
      "Episode 816 Reward: 29.0\n",
      "Episode 817 Reward: 95.0\n",
      "Episode 818 Reward: 83.0\n",
      "Episode 819 Reward: 87.0\n",
      "Timesteps: 24000, Policy Loss: 0.007656599042677214, Value Loss: 84.7890838623047, Entropy: 0.7395509004592895\n",
      "Episode 820 Reward: -385.0\n",
      "Episode 821 Reward: 95.0\n",
      "Episode 822 Reward: 76.0\n",
      "Episode 823 Reward: 91.0\n",
      "Episode 824 Reward: 87.0\n",
      "Episode 825 Reward: -390.0\n",
      "Episode 826 Reward: 91.0\n",
      "Episode 827 Reward: 95.0\n",
      "Episode 828 Reward: 95.0\n",
      "Episode 829 Reward: 91.0\n",
      "Episode 830 Reward: 52.0\n",
      "Episode 831 Reward: 91.0\n",
      "Episode 832 Reward: 29.0\n",
      "Episode 833 Reward: -395.0\n",
      "Episode 834 Reward: -390.0\n",
      "Episode 835 Reward: 87.0\n",
      "Episode 836 Reward: 91.0\n",
      "Episode 837 Reward: 91.0\n",
      "Episode 838 Reward: 95.0\n",
      "Episode 839 Reward: -395.0\n",
      "Episode 840 Reward: 19.0\n",
      "Episode 841 Reward: 95.0\n",
      "Episode 842 Reward: 95.0\n",
      "Episode 843 Reward: 95.0\n",
      "Episode 844 Reward: 91.0\n",
      "Episode 845 Reward: 95.0\n",
      "Episode 846 Reward: 95.0\n",
      "Episode 847 Reward: 95.0\n",
      "Episode 848 Reward: 91.0\n",
      "Episode 849 Reward: 91.0\n",
      "Episode 850 Reward: -395.0\n",
      "Episode 851 Reward: -390.0\n",
      "Episode 852 Reward: 95.0\n",
      "Episode 853 Reward: 91.0\n",
      "Episode 854 Reward: -47.0\n",
      "Episode 855 Reward: 87.0\n",
      "Episode 856 Reward: -395.0\n",
      "Episode 857 Reward: 95.0\n",
      "Episode 858 Reward: 57.0\n",
      "Episode 859 Reward: 95.0\n",
      "Episode 860 Reward: -395.0\n",
      "Episode 861 Reward: 95.0\n",
      "Episode 862 Reward: -380.0\n",
      "Episode 863 Reward: 76.0\n",
      "Episode 864 Reward: 95.0\n",
      "Episode 865 Reward: 95.0\n",
      "Episode 866 Reward: 95.0\n",
      "Episode 867 Reward: 57.0\n",
      "Episode 868 Reward: -24.0\n",
      "Episode 869 Reward: 24.0\n",
      "Episode 870 Reward: 91.0\n",
      "Episode 871 Reward: 95.0\n",
      "Episode 872 Reward: -395.0\n",
      "Episode 873 Reward: 95.0\n",
      "Episode 874 Reward: 95.0\n",
      "Episode 875 Reward: 95.0\n",
      "Episode 876 Reward: 95.0\n",
      "Episode 877 Reward: -395.0\n",
      "Episode 878 Reward: 95.0\n",
      "Episode 879 Reward: 95.0\n",
      "Episode 880 Reward: 95.0\n",
      "Episode 881 Reward: 95.0\n",
      "Episode 882 Reward: -380.0\n",
      "Episode 883 Reward: 24.0\n",
      "Episode 884 Reward: 95.0\n",
      "Episode 885 Reward: 19.0\n",
      "Episode 886 Reward: 87.0\n",
      "Episode 887 Reward: 95.0\n",
      "Episode 888 Reward: 45.0\n",
      "Episode 889 Reward: -395.0\n",
      "Episode 890 Reward: 95.0\n",
      "Episode 891 Reward: -380.0\n",
      "Episode 892 Reward: 32.0\n",
      "Episode 893 Reward: 95.0\n",
      "Episode 894 Reward: 95.0\n",
      "Episode 895 Reward: 95.0\n",
      "Episode 896 Reward: 95.0\n",
      "Episode 897 Reward: 47.0\n",
      "Episode 898 Reward: -390.0\n",
      "Episode 899 Reward: -390.0\n",
      "Episode 900 Reward: -390.0\n",
      "Episode 901 Reward: 91.0\n",
      "Episode 902 Reward: 7.0\n",
      "Episode 903 Reward: 91.0\n",
      "Episode 904 Reward: -395.0\n",
      "Episode 905 Reward: 95.0\n",
      "Episode 906 Reward: -390.0\n",
      "Episode 907 Reward: 95.0\n",
      "Episode 908 Reward: 95.0\n",
      "Episode 909 Reward: -10.0\n",
      "Episode 910 Reward: 95.0\n",
      "Episode 911 Reward: 41.0\n",
      "Episode 912 Reward: 87.0\n",
      "Episode 913 Reward: 95.0\n",
      "Episode 914 Reward: 95.0\n",
      "Episode 915 Reward: -390.0\n",
      "Episode 916 Reward: -390.0\n",
      "Episode 917 Reward: 95.0\n",
      "Episode 918 Reward: 95.0\n",
      "Episode 919 Reward: 95.0\n",
      "Episode 920 Reward: 41.0\n",
      "Episode 921 Reward: 95.0\n",
      "Episode 922 Reward: -390.0\n",
      "Episode 923 Reward: 91.0\n",
      "Episode 924 Reward: -14.0\n",
      "Episode 925 Reward: -390.0\n",
      "Episode 926 Reward: -390.0\n",
      "Episode 927 Reward: 95.0\n",
      "Episode 928 Reward: 95.0\n",
      "Episode 929 Reward: 91.0\n",
      "Episode 930 Reward: -385.0\n",
      "Episode 931 Reward: -390.0\n",
      "Episode 932 Reward: -375.0\n",
      "Episode 933 Reward: -395.0\n",
      "Episode 934 Reward: 95.0\n",
      "Episode 935 Reward: 87.0\n",
      "Episode 936 Reward: 95.0\n",
      "Episode 937 Reward: 87.0\n",
      "Episode 938 Reward: -395.0\n",
      "Episode 939 Reward: 91.0\n",
      "Episode 940 Reward: 95.0\n",
      "Episode 941 Reward: 95.0\n",
      "Episode 942 Reward: -395.0\n",
      "Episode 943 Reward: -395.0\n",
      "Episode 944 Reward: -390.0\n",
      "Episode 945 Reward: 91.0\n",
      "Timesteps: 27000, Policy Loss: 0.011409686545903597, Value Loss: 90.49705200195312, Entropy: 0.7206587374210358\n",
      "Episode 946 Reward: -390.0\n",
      "Episode 947 Reward: 76.0\n",
      "Episode 948 Reward: 95.0\n",
      "Episode 949 Reward: 91.0\n",
      "Episode 950 Reward: -390.0\n",
      "Episode 951 Reward: 95.0\n",
      "Episode 952 Reward: 12.0\n",
      "Episode 953 Reward: 9.0\n",
      "Episode 954 Reward: -395.0\n",
      "Episode 955 Reward: -390.0\n",
      "Episode 956 Reward: 95.0\n",
      "Episode 957 Reward: -385.0\n",
      "Episode 958 Reward: 95.0\n",
      "Episode 959 Reward: 95.0\n",
      "Episode 960 Reward: -395.0\n",
      "Episode 961 Reward: 91.0\n",
      "Episode 962 Reward: 95.0\n",
      "Episode 963 Reward: -27.0\n",
      "Episode 964 Reward: 95.0\n",
      "Episode 965 Reward: -385.0\n",
      "Episode 966 Reward: -395.0\n",
      "Episode 967 Reward: 57.0\n",
      "Episode 968 Reward: 95.0\n",
      "Episode 969 Reward: 95.0\n",
      "Episode 970 Reward: 95.0\n",
      "Episode 971 Reward: -395.0\n",
      "Episode 972 Reward: 95.0\n",
      "Episode 973 Reward: 87.0\n",
      "Episode 974 Reward: -395.0\n",
      "Episode 975 Reward: 95.0\n",
      "Episode 976 Reward: 91.0\n",
      "Episode 977 Reward: 14.0\n",
      "Episode 978 Reward: 95.0\n",
      "Episode 979 Reward: -385.0\n",
      "Episode 980 Reward: 91.0\n",
      "Episode 981 Reward: 95.0\n",
      "Episode 982 Reward: 95.0\n",
      "Episode 983 Reward: 44.0\n",
      "Episode 984 Reward: 0.0\n",
      "Episode 985 Reward: 20.0\n",
      "Episode 986 Reward: -395.0\n",
      "Episode 987 Reward: -390.0\n",
      "Episode 988 Reward: 95.0\n",
      "Episode 989 Reward: -385.0\n",
      "Episode 990 Reward: 95.0\n",
      "Episode 991 Reward: 95.0\n",
      "Episode 992 Reward: 95.0\n",
      "Episode 993 Reward: 52.0\n",
      "Episode 994 Reward: 95.0\n",
      "Episode 995 Reward: 20.0\n",
      "Episode 996 Reward: 52.0\n",
      "Episode 997 Reward: 95.0\n",
      "Episode 998 Reward: -395.0\n",
      "Episode 999 Reward: 95.0\n",
      "Episode 1000 Reward: -395.0\n",
      "Episode 1001 Reward: 95.0\n",
      "Episode 1002 Reward: -395.0\n",
      "Episode 1003 Reward: -395.0\n",
      "Episode 1004 Reward: -395.0\n",
      "Episode 1005 Reward: 95.0\n",
      "Episode 1006 Reward: -5.0\n",
      "Episode 1007 Reward: 68.0\n",
      "Episode 1008 Reward: 95.0\n",
      "Episode 1009 Reward: 95.0\n",
      "Episode 1010 Reward: -375.0\n",
      "Episode 1011 Reward: 91.0\n",
      "Episode 1012 Reward: 52.0\n",
      "Episode 1013 Reward: -395.0\n",
      "Episode 1014 Reward: -400.0\n",
      "Episode 1015 Reward: 95.0\n",
      "Episode 1016 Reward: 29.0\n",
      "Episode 1017 Reward: 33.0\n",
      "Episode 1018 Reward: 95.0\n",
      "Episode 1019 Reward: 95.0\n",
      "Episode 1020 Reward: 95.0\n",
      "Episode 1021 Reward: 5.0\n",
      "Episode 1022 Reward: 95.0\n",
      "Episode 1023 Reward: 95.0\n",
      "Episode 1024 Reward: 95.0\n",
      "Episode 1025 Reward: -390.0\n",
      "Episode 1026 Reward: 95.0\n",
      "Episode 1027 Reward: 95.0\n",
      "Episode 1028 Reward: -390.0\n",
      "Episode 1029 Reward: 34.0\n",
      "Episode 1030 Reward: 28.0\n",
      "Episode 1031 Reward: 48.0\n",
      "Episode 1032 Reward: 95.0\n",
      "Episode 1033 Reward: 95.0\n",
      "Episode 1034 Reward: -400.0\n",
      "Episode 1035 Reward: -395.0\n",
      "Episode 1036 Reward: 30.0\n",
      "Episode 1037 Reward: 95.0\n",
      "Episode 1038 Reward: -380.0\n",
      "Episode 1039 Reward: -385.0\n",
      "Episode 1040 Reward: 95.0\n",
      "Episode 1041 Reward: 91.0\n",
      "Episode 1042 Reward: 95.0\n",
      "Episode 1043 Reward: 91.0\n",
      "Episode 1044 Reward: 91.0\n",
      "Episode 1045 Reward: 95.0\n",
      "Episode 1046 Reward: -96.0\n",
      "Episode 1047 Reward: 21.0\n",
      "Episode 1048 Reward: 95.0\n",
      "Episode 1049 Reward: 95.0\n",
      "Episode 1050 Reward: 95.0\n",
      "Episode 1051 Reward: -390.0\n",
      "Episode 1052 Reward: -395.0\n",
      "Episode 1053 Reward: -390.0\n",
      "Episode 1054 Reward: 95.0\n",
      "Episode 1055 Reward: 87.0\n",
      "Episode 1056 Reward: -395.0\n",
      "Episode 1057 Reward: 95.0\n",
      "Episode 1058 Reward: 33.0\n",
      "Episode 1059 Reward: 72.0\n",
      "Episode 1060 Reward: -395.0\n",
      "Episode 1061 Reward: 95.0\n",
      "Episode 1062 Reward: 91.0\n",
      "Episode 1063 Reward: -385.0\n",
      "Timesteps: 30000, Policy Loss: 0.007026111712155369, Value Loss: 91.33105697631837, Entropy: 0.7426336884498597\n",
      "Episode 1064 Reward: -395.0\n",
      "Episode 1065 Reward: -10.0\n",
      "Episode 1066 Reward: 33.0\n",
      "Episode 1067 Reward: 95.0\n",
      "Episode 1068 Reward: 87.0\n",
      "Episode 1069 Reward: 91.0\n",
      "Episode 1070 Reward: 87.0\n",
      "Episode 1071 Reward: -395.0\n",
      "Episode 1072 Reward: 95.0\n",
      "Episode 1073 Reward: -13.0\n",
      "Episode 1074 Reward: 95.0\n",
      "Episode 1075 Reward: -395.0\n",
      "Episode 1076 Reward: 33.0\n",
      "Episode 1077 Reward: -395.0\n",
      "Episode 1078 Reward: -400.0\n",
      "Episode 1079 Reward: -390.0\n",
      "Episode 1080 Reward: 52.0\n",
      "Episode 1081 Reward: 95.0\n",
      "Episode 1082 Reward: -390.0\n",
      "Episode 1083 Reward: 91.0\n",
      "Episode 1084 Reward: -390.0\n",
      "Episode 1085 Reward: 52.0\n",
      "Episode 1086 Reward: 34.0\n",
      "Episode 1087 Reward: 91.0\n",
      "Episode 1088 Reward: 95.0\n",
      "Episode 1089 Reward: -390.0\n",
      "Episode 1090 Reward: -390.0\n",
      "Episode 1091 Reward: -390.0\n",
      "Episode 1092 Reward: 95.0\n",
      "Episode 1093 Reward: 91.0\n",
      "Episode 1094 Reward: -400.0\n",
      "Episode 1095 Reward: -385.0\n",
      "Episode 1096 Reward: 95.0\n",
      "Episode 1097 Reward: 91.0\n",
      "Episode 1098 Reward: 29.0\n",
      "Episode 1099 Reward: -52.0\n",
      "Episode 1100 Reward: 95.0\n",
      "Episode 1101 Reward: 95.0\n",
      "Episode 1102 Reward: 95.0\n",
      "Episode 1103 Reward: 87.0\n",
      "Episode 1104 Reward: 91.0\n",
      "Episode 1105 Reward: 71.0\n",
      "Episode 1106 Reward: 43.0\n",
      "Episode 1107 Reward: 67.0\n",
      "Episode 1108 Reward: 1.0\n",
      "Episode 1109 Reward: 57.0\n",
      "Episode 1110 Reward: 95.0\n",
      "Episode 1111 Reward: 3.0\n",
      "Episode 1112 Reward: 95.0\n",
      "Episode 1113 Reward: 91.0\n",
      "Episode 1114 Reward: -31.0\n",
      "Episode 1115 Reward: -395.0\n",
      "Episode 1116 Reward: 95.0\n",
      "Episode 1117 Reward: 95.0\n",
      "Episode 1118 Reward: 95.0\n",
      "Episode 1119 Reward: 95.0\n",
      "Episode 1120 Reward: 5.0\n",
      "Episode 1121 Reward: 95.0\n",
      "Episode 1122 Reward: 87.0\n",
      "Episode 1123 Reward: 95.0\n",
      "Episode 1124 Reward: -380.0\n",
      "Episode 1125 Reward: -400.0\n",
      "Episode 1126 Reward: 95.0\n",
      "Episode 1127 Reward: -390.0\n",
      "Episode 1128 Reward: 95.0\n",
      "Episode 1129 Reward: 91.0\n",
      "Episode 1130 Reward: -380.0\n",
      "Episode 1131 Reward: 95.0\n",
      "Episode 1132 Reward: 95.0\n",
      "Episode 1133 Reward: 91.0\n",
      "Episode 1134 Reward: -390.0\n",
      "Episode 1135 Reward: 95.0\n",
      "Episode 1136 Reward: 95.0\n",
      "Episode 1137 Reward: 95.0\n",
      "Episode 1138 Reward: -390.0\n",
      "Episode 1139 Reward: -390.0\n",
      "Episode 1140 Reward: 95.0\n",
      "Episode 1141 Reward: 95.0\n",
      "Episode 1142 Reward: 33.0\n",
      "Episode 1143 Reward: 95.0\n",
      "Episode 1144 Reward: 95.0\n",
      "Episode 1145 Reward: -395.0\n",
      "Episode 1146 Reward: 87.0\n",
      "Episode 1147 Reward: 95.0\n",
      "Episode 1148 Reward: 95.0\n",
      "Episode 1149 Reward: 95.0\n",
      "Episode 1150 Reward: -390.0\n",
      "Episode 1151 Reward: -390.0\n",
      "Episode 1152 Reward: 91.0\n",
      "Episode 1153 Reward: 95.0\n",
      "Episode 1154 Reward: 9.0\n",
      "Episode 1155 Reward: -395.0\n",
      "Episode 1156 Reward: -385.0\n",
      "Episode 1157 Reward: 95.0\n",
      "Episode 1158 Reward: 95.0\n",
      "Episode 1159 Reward: 57.0\n",
      "Episode 1160 Reward: 95.0\n",
      "Episode 1161 Reward: 95.0\n",
      "Episode 1162 Reward: 91.0\n",
      "Episode 1163 Reward: 67.0\n",
      "Episode 1164 Reward: -400.0\n",
      "Episode 1165 Reward: 83.0\n",
      "Episode 1166 Reward: 52.0\n",
      "Episode 1167 Reward: -390.0\n",
      "Episode 1168 Reward: 91.0\n",
      "Episode 1169 Reward: 91.0\n",
      "Episode 1170 Reward: 57.0\n",
      "Episode 1171 Reward: 91.0\n",
      "Episode 1172 Reward: 95.0\n",
      "Episode 1173 Reward: 76.0\n",
      "Episode 1174 Reward: 95.0\n",
      "Episode 1175 Reward: -395.0\n",
      "Episode 1176 Reward: 95.0\n",
      "Episode 1177 Reward: 72.0\n",
      "Episode 1178 Reward: 95.0\n",
      "Episode 1179 Reward: 95.0\n",
      "Episode 1180 Reward: -385.0\n",
      "Episode 1181 Reward: 95.0\n",
      "Episode 1182 Reward: 95.0\n",
      "Episode 1183 Reward: 87.0\n",
      "Episode 1184 Reward: 68.0\n",
      "Episode 1185 Reward: 95.0\n",
      "Episode 1186 Reward: 95.0\n",
      "Episode 1187 Reward: 91.0\n",
      "Episode 1188 Reward: 87.0\n",
      "Episode 1189 Reward: 95.0\n",
      "Episode 1190 Reward: 95.0\n",
      "Episode 1191 Reward: -56.0\n",
      "Episode 1192 Reward: 95.0\n",
      "Episode 1193 Reward: 52.0\n",
      "Episode 1194 Reward: -405.0\n",
      "Episode 1195 Reward: 95.0\n",
      "Episode 1196 Reward: -390.0\n",
      "Timesteps: 33000, Policy Loss: 0.004570786118856596, Value Loss: 94.76333312988281, Entropy: 0.7438200354576111\n",
      "Episode 1197 Reward: -400.0\n",
      "Episode 1198 Reward: 91.0\n",
      "Episode 1199 Reward: 95.0\n",
      "Episode 1200 Reward: -395.0\n",
      "Episode 1201 Reward: 95.0\n",
      "Episode 1202 Reward: 95.0\n",
      "Episode 1203 Reward: -395.0\n",
      "Episode 1204 Reward: 95.0\n",
      "Episode 1205 Reward: 68.0\n",
      "Episode 1206 Reward: 95.0\n",
      "Episode 1207 Reward: -385.0\n",
      "Episode 1208 Reward: 91.0\n",
      "Episode 1209 Reward: 95.0\n",
      "Episode 1210 Reward: 95.0\n",
      "Episode 1211 Reward: 95.0\n",
      "Episode 1212 Reward: 95.0\n",
      "Episode 1213 Reward: -385.0\n",
      "Episode 1214 Reward: 95.0\n",
      "Episode 1215 Reward: 95.0\n",
      "Episode 1216 Reward: 14.0\n",
      "Episode 1217 Reward: 95.0\n",
      "Episode 1218 Reward: 33.0\n",
      "Episode 1219 Reward: -400.0\n",
      "Episode 1220 Reward: 72.0\n",
      "Episode 1221 Reward: 95.0\n",
      "Episode 1222 Reward: 95.0\n",
      "Episode 1223 Reward: 91.0\n",
      "Episode 1224 Reward: 95.0\n",
      "Episode 1225 Reward: 68.0\n",
      "Episode 1226 Reward: 95.0\n",
      "Episode 1227 Reward: 95.0\n",
      "Episode 1228 Reward: 95.0\n",
      "Episode 1229 Reward: 95.0\n",
      "Episode 1230 Reward: 95.0\n",
      "Episode 1231 Reward: 95.0\n",
      "Episode 1232 Reward: 5.0\n",
      "Episode 1233 Reward: -395.0\n",
      "Episode 1234 Reward: 95.0\n",
      "Episode 1235 Reward: 66.0\n",
      "Episode 1236 Reward: 91.0\n",
      "Episode 1237 Reward: -395.0\n",
      "Episode 1238 Reward: 95.0\n",
      "Episode 1239 Reward: 95.0\n",
      "Episode 1240 Reward: 91.0\n",
      "Episode 1241 Reward: 95.0\n",
      "Episode 1242 Reward: 95.0\n",
      "Episode 1243 Reward: 95.0\n",
      "Episode 1244 Reward: 95.0\n",
      "Episode 1245 Reward: 95.0\n",
      "Episode 1246 Reward: 95.0\n",
      "Episode 1247 Reward: 95.0\n",
      "Episode 1248 Reward: 95.0\n",
      "Episode 1249 Reward: 95.0\n",
      "Episode 1250 Reward: 95.0\n",
      "Episode 1251 Reward: -395.0\n",
      "Episode 1252 Reward: 91.0\n",
      "Episode 1253 Reward: 95.0\n",
      "Episode 1254 Reward: -29.0\n",
      "Episode 1255 Reward: -395.0\n",
      "Episode 1256 Reward: -390.0\n",
      "Episode 1257 Reward: 95.0\n",
      "Episode 1258 Reward: -390.0\n",
      "Episode 1259 Reward: -67.0\n",
      "Episode 1260 Reward: 38.0\n",
      "Episode 1261 Reward: 14.0\n",
      "Episode 1262 Reward: 45.0\n",
      "Episode 1263 Reward: 95.0\n",
      "Episode 1264 Reward: 95.0\n",
      "Episode 1265 Reward: 95.0\n",
      "Episode 1266 Reward: 95.0\n",
      "Episode 1267 Reward: -400.0\n",
      "Episode 1268 Reward: 95.0\n",
      "Episode 1269 Reward: 95.0\n",
      "Episode 1270 Reward: -98.0\n",
      "Episode 1271 Reward: 95.0\n",
      "Episode 1272 Reward: 95.0\n",
      "Episode 1273 Reward: -77.0\n",
      "Episode 1274 Reward: 95.0\n",
      "Episode 1275 Reward: 3.0\n",
      "Episode 1276 Reward: -395.0\n",
      "Episode 1277 Reward: 95.0\n",
      "Episode 1278 Reward: 91.0\n",
      "Episode 1279 Reward: 47.0\n",
      "Episode 1280 Reward: -31.0\n",
      "Episode 1281 Reward: 95.0\n",
      "Episode 1282 Reward: -395.0\n",
      "Episode 1283 Reward: 95.0\n",
      "Episode 1284 Reward: 95.0\n",
      "Episode 1285 Reward: 95.0\n",
      "Episode 1286 Reward: 95.0\n",
      "Episode 1287 Reward: 95.0\n",
      "Episode 1288 Reward: 95.0\n",
      "Episode 1289 Reward: 95.0\n",
      "Episode 1290 Reward: 95.0\n",
      "Episode 1291 Reward: 95.0\n",
      "Episode 1292 Reward: -390.0\n",
      "Episode 1293 Reward: 95.0\n",
      "Episode 1294 Reward: 95.0\n",
      "Episode 1295 Reward: -395.0\n",
      "Episode 1296 Reward: 95.0\n",
      "Episode 1297 Reward: 91.0\n",
      "Episode 1298 Reward: -390.0\n",
      "Episode 1299 Reward: 95.0\n",
      "Episode 1300 Reward: 95.0\n",
      "Episode 1301 Reward: 95.0\n",
      "Episode 1302 Reward: 52.0\n",
      "Episode 1303 Reward: 71.0\n",
      "Episode 1304 Reward: 95.0\n",
      "Episode 1305 Reward: 95.0\n",
      "Episode 1306 Reward: 95.0\n",
      "Episode 1307 Reward: 95.0\n",
      "Episode 1308 Reward: 95.0\n",
      "Episode 1309 Reward: 48.0\n",
      "Episode 1310 Reward: 95.0\n",
      "Episode 1311 Reward: 95.0\n",
      "Episode 1312 Reward: 95.0\n",
      "Episode 1313 Reward: -390.0\n",
      "Episode 1314 Reward: 95.0\n",
      "Episode 1315 Reward: 95.0\n",
      "Episode 1316 Reward: -395.0\n",
      "Episode 1317 Reward: 95.0\n",
      "Episode 1318 Reward: 95.0\n",
      "Episode 1319 Reward: -395.0\n",
      "Episode 1320 Reward: 95.0\n",
      "Episode 1321 Reward: -107.0\n",
      "Episode 1322 Reward: 91.0\n",
      "Episode 1323 Reward: -390.0\n",
      "Episode 1324 Reward: 95.0\n",
      "Episode 1325 Reward: 91.0\n",
      "Episode 1326 Reward: 95.0\n",
      "Episode 1327 Reward: -395.0\n",
      "Episode 1328 Reward: 95.0\n",
      "Episode 1329 Reward: 67.0\n",
      "Episode 1330 Reward: 95.0\n",
      "Episode 1331 Reward: -395.0\n",
      "Episode 1332 Reward: 95.0\n",
      "Episode 1333 Reward: 95.0\n",
      "Episode 1334 Reward: -161.0\n",
      "Episode 1335 Reward: 27.0\n",
      "Episode 1336 Reward: 7.0\n",
      "Episode 1337 Reward: 91.0\n",
      "Episode 1338 Reward: 68.0\n",
      "Episode 1339 Reward: 91.0\n",
      "Episode 1340 Reward: 71.0\n",
      "Episode 1341 Reward: 87.0\n",
      "Episode 1342 Reward: 95.0\n",
      "Episode 1343 Reward: 91.0\n",
      "Episode 1344 Reward: -72.0\n",
      "Episode 1345 Reward: 91.0\n",
      "Episode 1346 Reward: 95.0\n",
      "Episode 1347 Reward: 91.0\n",
      "Episode 1348 Reward: -400.0\n",
      "Episode 1349 Reward: 76.0\n",
      "Episode 1350 Reward: 95.0\n",
      "Episode 1351 Reward: -385.0\n",
      "Episode 1352 Reward: 95.0\n",
      "Episode 1353 Reward: 95.0\n",
      "Episode 1354 Reward: -390.0\n",
      "Episode 1355 Reward: 95.0\n",
      "Episode 1356 Reward: 95.0\n",
      "Episode 1357 Reward: 95.0\n",
      "Episode 1358 Reward: 95.0\n",
      "Episode 1359 Reward: 95.0\n",
      "Episode 1360 Reward: -390.0\n",
      "Episode 1361 Reward: 95.0\n",
      "Episode 1362 Reward: 95.0\n",
      "Episode 1363 Reward: -5.0\n",
      "Episode 1364 Reward: 87.0\n",
      "Episode 1365 Reward: 95.0\n",
      "Episode 1366 Reward: 95.0\n",
      "Episode 1367 Reward: -134.0\n",
      "Episode 1368 Reward: 95.0\n",
      "Episode 1369 Reward: 95.0\n",
      "Episode 1370 Reward: 95.0\n",
      "Episode 1371 Reward: -395.0\n",
      "Timesteps: 36000, Policy Loss: 0.0009280498997579656, Value Loss: 100.64380722045898, Entropy: 0.7620088458061218\n",
      "Episode 1372 Reward: 53.0\n",
      "Episode 1373 Reward: 95.0\n",
      "Episode 1374 Reward: 95.0\n",
      "Episode 1375 Reward: 95.0\n",
      "Episode 1376 Reward: -400.0\n",
      "Episode 1377 Reward: 91.0\n",
      "Episode 1378 Reward: 95.0\n",
      "Episode 1379 Reward: 91.0\n",
      "Episode 1380 Reward: 95.0\n",
      "Episode 1381 Reward: -395.0\n",
      "Episode 1382 Reward: 87.0\n",
      "Episode 1383 Reward: -395.0\n",
      "Episode 1384 Reward: 95.0\n",
      "Episode 1385 Reward: 70.0\n",
      "Episode 1386 Reward: 38.0\n",
      "Episode 1387 Reward: -405.0\n",
      "Episode 1388 Reward: 95.0\n",
      "Episode 1389 Reward: 95.0\n",
      "Episode 1390 Reward: 91.0\n",
      "Episode 1391 Reward: 76.0\n",
      "Episode 1392 Reward: 91.0\n",
      "Episode 1393 Reward: 91.0\n",
      "Episode 1394 Reward: -395.0\n",
      "Episode 1395 Reward: -390.0\n",
      "Episode 1396 Reward: 91.0\n",
      "Episode 1397 Reward: -390.0\n",
      "Episode 1398 Reward: 95.0\n",
      "Episode 1399 Reward: -168.0\n",
      "Episode 1400 Reward: -395.0\n",
      "Episode 1401 Reward: 95.0\n",
      "Episode 1402 Reward: -395.0\n",
      "Episode 1403 Reward: -46.0\n",
      "Episode 1404 Reward: -390.0\n",
      "Episode 1405 Reward: 10.0\n",
      "Episode 1406 Reward: -400.0\n",
      "Episode 1407 Reward: -395.0\n",
      "Episode 1408 Reward: -400.0\n",
      "Episode 1409 Reward: 95.0\n",
      "Episode 1410 Reward: 19.0\n",
      "Episode 1411 Reward: 91.0\n",
      "Episode 1412 Reward: -400.0\n",
      "Episode 1413 Reward: 95.0\n",
      "Episode 1414 Reward: 95.0\n",
      "Episode 1415 Reward: 95.0\n",
      "Episode 1416 Reward: 87.0\n",
      "Episode 1417 Reward: -400.0\n",
      "Episode 1418 Reward: 95.0\n",
      "Episode 1419 Reward: 95.0\n",
      "Episode 1420 Reward: 95.0\n",
      "Episode 1421 Reward: 95.0\n",
      "Episode 1422 Reward: 95.0\n",
      "Episode 1423 Reward: 95.0\n",
      "Episode 1424 Reward: 95.0\n",
      "Episode 1425 Reward: -35.0\n",
      "Episode 1426 Reward: -400.0\n",
      "Episode 1427 Reward: 95.0\n",
      "Episode 1428 Reward: 95.0\n",
      "Episode 1429 Reward: -390.0\n",
      "Episode 1430 Reward: -405.0\n",
      "Episode 1431 Reward: -395.0\n",
      "Episode 1432 Reward: 48.0\n",
      "Episode 1433 Reward: 95.0\n",
      "Episode 1434 Reward: 95.0\n",
      "Episode 1435 Reward: -400.0\n",
      "Episode 1436 Reward: -395.0\n",
      "Episode 1437 Reward: 95.0\n",
      "Episode 1438 Reward: 0.0\n",
      "Episode 1439 Reward: 95.0\n",
      "Episode 1440 Reward: -133.0\n",
      "Episode 1441 Reward: 95.0\n",
      "Episode 1442 Reward: 57.0\n",
      "Episode 1443 Reward: 95.0\n",
      "Episode 1444 Reward: 87.0\n",
      "Episode 1445 Reward: -400.0\n",
      "Episode 1446 Reward: -52.0\n",
      "Episode 1447 Reward: -400.0\n",
      "Episode 1448 Reward: 14.0\n",
      "Episode 1449 Reward: 95.0\n",
      "Episode 1450 Reward: -68.0\n",
      "Episode 1451 Reward: 53.0\n",
      "Episode 1452 Reward: 95.0\n",
      "Episode 1453 Reward: 91.0\n",
      "Episode 1454 Reward: 95.0\n",
      "Episode 1455 Reward: 19.0\n",
      "Episode 1456 Reward: 87.0\n",
      "Episode 1457 Reward: 91.0\n",
      "Episode 1458 Reward: -395.0\n",
      "Episode 1459 Reward: -385.0\n",
      "Episode 1460 Reward: 95.0\n",
      "Episode 1461 Reward: -395.0\n",
      "Episode 1462 Reward: -34.0\n",
      "Episode 1463 Reward: 95.0\n",
      "Episode 1464 Reward: 95.0\n",
      "Episode 1465 Reward: 95.0\n",
      "Episode 1466 Reward: 91.0\n",
      "Episode 1467 Reward: -48.0\n",
      "Episode 1468 Reward: -80.0\n",
      "Episode 1469 Reward: -19.0\n",
      "Episode 1470 Reward: 34.0\n",
      "Episode 1471 Reward: 95.0\n",
      "Episode 1472 Reward: 91.0\n",
      "Episode 1473 Reward: -395.0\n",
      "Episode 1474 Reward: 95.0\n",
      "Episode 1475 Reward: 95.0\n",
      "Episode 1476 Reward: 95.0\n",
      "Episode 1477 Reward: 95.0\n",
      "Episode 1478 Reward: 19.0\n",
      "Episode 1479 Reward: -400.0\n",
      "Episode 1480 Reward: 95.0\n",
      "Episode 1481 Reward: 95.0\n",
      "Episode 1482 Reward: -48.0\n",
      "Episode 1483 Reward: 71.0\n",
      "Episode 1484 Reward: 91.0\n",
      "Episode 1485 Reward: -390.0\n",
      "Episode 1486 Reward: 95.0\n",
      "Episode 1487 Reward: 10.0\n",
      "Episode 1488 Reward: -52.0\n",
      "Episode 1489 Reward: -32.0\n",
      "Episode 1490 Reward: 68.0\n",
      "Episode 1491 Reward: 95.0\n",
      "Episode 1492 Reward: 91.0\n",
      "Episode 1493 Reward: 95.0\n",
      "Episode 1494 Reward: 95.0\n",
      "Timesteps: 39000, Policy Loss: 3.5846176446163726e-05, Value Loss: 96.87208099365235, Entropy: 0.6939631104469299\n",
      "Episode 1495 Reward: -395.0\n",
      "Episode 1496 Reward: 19.0\n",
      "Episode 1497 Reward: -42.0\n",
      "Episode 1498 Reward: 91.0\n",
      "Episode 1499 Reward: 91.0\n",
      "Episode 1500 Reward: -48.0\n",
      "Episode 1501 Reward: -10.0\n",
      "Episode 1502 Reward: 30.0\n",
      "Episode 1503 Reward: 57.0\n",
      "Episode 1504 Reward: -33.0\n",
      "Episode 1505 Reward: 95.0\n",
      "Episode 1506 Reward: -395.0\n",
      "Episode 1507 Reward: -395.0\n",
      "Episode 1508 Reward: -395.0\n",
      "Episode 1509 Reward: -38.0\n",
      "Episode 1510 Reward: 95.0\n",
      "Episode 1511 Reward: -395.0\n",
      "Episode 1512 Reward: -395.0\n",
      "Episode 1513 Reward: 91.0\n",
      "Episode 1514 Reward: 95.0\n",
      "Episode 1515 Reward: 91.0\n",
      "Episode 1516 Reward: 91.0\n",
      "Episode 1517 Reward: -395.0\n",
      "Episode 1518 Reward: 95.0\n",
      "Episode 1519 Reward: 91.0\n",
      "Episode 1520 Reward: -400.0\n",
      "Episode 1521 Reward: -38.0\n",
      "Episode 1522 Reward: 95.0\n",
      "Episode 1523 Reward: 95.0\n",
      "Episode 1524 Reward: 95.0\n",
      "Episode 1525 Reward: -400.0\n",
      "Episode 1526 Reward: 95.0\n",
      "Episode 1527 Reward: 91.0\n",
      "Episode 1528 Reward: 95.0\n",
      "Episode 1529 Reward: 95.0\n",
      "Episode 1530 Reward: 95.0\n",
      "Episode 1531 Reward: -5.0\n",
      "Episode 1532 Reward: -395.0\n",
      "Episode 1533 Reward: -395.0\n",
      "Episode 1534 Reward: 95.0\n",
      "Episode 1535 Reward: -395.0\n",
      "Episode 1536 Reward: 95.0\n",
      "Episode 1537 Reward: 95.0\n",
      "Episode 1538 Reward: -400.0\n",
      "Episode 1539 Reward: 95.0\n",
      "Episode 1540 Reward: -395.0\n",
      "Episode 1541 Reward: -400.0\n",
      "Episode 1542 Reward: 95.0\n",
      "Episode 1543 Reward: 91.0\n",
      "Episode 1544 Reward: 95.0\n",
      "Episode 1545 Reward: 95.0\n",
      "Episode 1546 Reward: 95.0\n",
      "Episode 1547 Reward: 91.0\n",
      "Episode 1548 Reward: 57.0\n",
      "Episode 1549 Reward: 95.0\n",
      "Episode 1550 Reward: 95.0\n",
      "Episode 1551 Reward: 58.0\n",
      "Episode 1552 Reward: 10.0\n",
      "Episode 1553 Reward: 67.0\n",
      "Episode 1554 Reward: -395.0\n",
      "Episode 1555 Reward: -395.0\n",
      "Episode 1556 Reward: 30.0\n",
      "Episode 1557 Reward: -390.0\n",
      "Episode 1558 Reward: 95.0\n",
      "Episode 1559 Reward: 95.0\n",
      "Episode 1560 Reward: 57.0\n",
      "Episode 1561 Reward: 91.0\n",
      "Episode 1562 Reward: 95.0\n",
      "Episode 1563 Reward: -390.0\n",
      "Episode 1564 Reward: -32.0\n",
      "Episode 1565 Reward: 91.0\n",
      "Episode 1566 Reward: 95.0\n",
      "Episode 1567 Reward: 95.0\n",
      "Episode 1568 Reward: 95.0\n",
      "Episode 1569 Reward: 26.0\n",
      "Episode 1570 Reward: 91.0\n",
      "Episode 1571 Reward: -395.0\n",
      "Episode 1572 Reward: -395.0\n",
      "Episode 1573 Reward: -400.0\n",
      "Episode 1574 Reward: 95.0\n",
      "Episode 1575 Reward: -395.0\n",
      "Episode 1576 Reward: 95.0\n",
      "Episode 1577 Reward: 95.0\n",
      "Episode 1578 Reward: 95.0\n",
      "Episode 1579 Reward: -395.0\n",
      "Episode 1580 Reward: 91.0\n",
      "Episode 1581 Reward: -390.0\n",
      "Episode 1582 Reward: 3.0\n",
      "Episode 1583 Reward: 95.0\n",
      "Episode 1584 Reward: -400.0\n",
      "Episode 1585 Reward: 87.0\n",
      "Episode 1586 Reward: 33.0\n",
      "Episode 1587 Reward: 91.0\n",
      "Episode 1588 Reward: -38.0\n",
      "Episode 1589 Reward: 95.0\n",
      "Episode 1590 Reward: 95.0\n",
      "Episode 1591 Reward: -395.0\n",
      "Episode 1592 Reward: 95.0\n",
      "Episode 1593 Reward: 95.0\n",
      "Episode 1594 Reward: 3.0\n",
      "Episode 1595 Reward: -395.0\n",
      "Episode 1596 Reward: 95.0\n",
      "Episode 1597 Reward: 57.0\n",
      "Episode 1598 Reward: 95.0\n",
      "Episode 1599 Reward: 95.0\n",
      "Episode 1600 Reward: 42.0\n",
      "Episode 1601 Reward: -24.0\n",
      "Episode 1602 Reward: 95.0\n",
      "Episode 1603 Reward: -390.0\n",
      "Episode 1604 Reward: 19.0\n",
      "Episode 1605 Reward: -390.0\n",
      "Episode 1606 Reward: 95.0\n",
      "Episode 1607 Reward: 87.0\n",
      "Episode 1608 Reward: 72.0\n",
      "Episode 1609 Reward: -395.0\n",
      "Episode 1610 Reward: 95.0\n",
      "Episode 1611 Reward: 95.0\n",
      "Episode 1612 Reward: 95.0\n",
      "Episode 1613 Reward: 49.0\n",
      "Episode 1614 Reward: 95.0\n",
      "Episode 1615 Reward: 64.0\n",
      "Episode 1616 Reward: 76.0\n",
      "Episode 1617 Reward: 95.0\n",
      "Episode 1618 Reward: -390.0\n",
      "Timesteps: 42000, Policy Loss: 0.000982104805855011, Value Loss: 96.48613204956055, Entropy: 0.7003667116165161\n",
      "Episode 1619 Reward: -400.0\n",
      "Episode 1620 Reward: -390.0\n",
      "Episode 1621 Reward: -4.0\n",
      "Episode 1622 Reward: -400.0\n",
      "Episode 1623 Reward: 95.0\n",
      "Episode 1624 Reward: -395.0\n",
      "Episode 1625 Reward: -105.0\n",
      "Episode 1626 Reward: 95.0\n",
      "Episode 1627 Reward: 95.0\n",
      "Episode 1628 Reward: 95.0\n",
      "Episode 1629 Reward: 95.0\n",
      "Episode 1630 Reward: -400.0\n",
      "Episode 1631 Reward: -48.0\n",
      "Episode 1632 Reward: -390.0\n",
      "Episode 1633 Reward: -395.0\n",
      "Episode 1634 Reward: 91.0\n",
      "Episode 1635 Reward: -405.0\n",
      "Episode 1636 Reward: -385.0\n",
      "Episode 1637 Reward: 95.0\n",
      "Episode 1638 Reward: 95.0\n",
      "Episode 1639 Reward: -395.0\n",
      "Episode 1640 Reward: 95.0\n",
      "Episode 1641 Reward: 95.0\n",
      "Episode 1642 Reward: 72.0\n",
      "Episode 1643 Reward: 95.0\n",
      "Episode 1644 Reward: -405.0\n",
      "Episode 1645 Reward: 95.0\n",
      "Episode 1646 Reward: 91.0\n",
      "Episode 1647 Reward: -400.0\n",
      "Episode 1648 Reward: 63.0\n",
      "Episode 1649 Reward: -395.0\n",
      "Episode 1650 Reward: 91.0\n",
      "Episode 1651 Reward: 95.0\n",
      "Episode 1652 Reward: 95.0\n",
      "Episode 1653 Reward: 87.0\n",
      "Episode 1654 Reward: -400.0\n",
      "Episode 1655 Reward: 57.0\n",
      "Episode 1656 Reward: 95.0\n",
      "Episode 1657 Reward: -12.0\n",
      "Episode 1658 Reward: -395.0\n",
      "Episode 1659 Reward: 95.0\n",
      "Episode 1660 Reward: 95.0\n",
      "Episode 1661 Reward: -395.0\n",
      "Episode 1662 Reward: 91.0\n",
      "Episode 1663 Reward: 95.0\n",
      "Episode 1664 Reward: -395.0\n",
      "Episode 1665 Reward: 14.0\n",
      "Episode 1666 Reward: -43.0\n",
      "Episode 1667 Reward: 87.0\n",
      "Episode 1668 Reward: 29.0\n",
      "Episode 1669 Reward: -390.0\n",
      "Episode 1670 Reward: 95.0\n",
      "Episode 1671 Reward: 95.0\n",
      "Episode 1672 Reward: -9.0\n",
      "Episode 1673 Reward: -400.0\n",
      "Episode 1674 Reward: 19.0\n",
      "Episode 1675 Reward: 91.0\n",
      "Episode 1676 Reward: -400.0\n",
      "Episode 1677 Reward: -385.0\n",
      "Episode 1678 Reward: -5.0\n",
      "Episode 1679 Reward: 95.0\n",
      "Episode 1680 Reward: 95.0\n",
      "Episode 1681 Reward: -29.0\n",
      "Episode 1682 Reward: 91.0\n",
      "Episode 1683 Reward: 95.0\n",
      "Episode 1684 Reward: 95.0\n",
      "Episode 1685 Reward: 95.0\n",
      "Episode 1686 Reward: -390.0\n",
      "Episode 1687 Reward: 95.0\n",
      "Episode 1688 Reward: 91.0\n",
      "Episode 1689 Reward: 95.0\n",
      "Episode 1690 Reward: 76.0\n",
      "Episode 1691 Reward: -390.0\n",
      "Episode 1692 Reward: 95.0\n",
      "Episode 1693 Reward: -385.0\n",
      "Episode 1694 Reward: 91.0\n",
      "Episode 1695 Reward: -395.0\n",
      "Episode 1696 Reward: 48.0\n",
      "Episode 1697 Reward: 95.0\n",
      "Episode 1698 Reward: 76.0\n",
      "Episode 1699 Reward: -395.0\n",
      "Episode 1700 Reward: -400.0\n",
      "Episode 1701 Reward: 95.0\n",
      "Episode 1702 Reward: 72.0\n",
      "Episode 1703 Reward: 76.0\n",
      "Episode 1704 Reward: -400.0\n",
      "Episode 1705 Reward: 91.0\n",
      "Episode 1706 Reward: 91.0\n",
      "Episode 1707 Reward: -395.0\n",
      "Episode 1708 Reward: 14.0\n",
      "Episode 1709 Reward: -400.0\n",
      "Episode 1710 Reward: 95.0\n",
      "Episode 1711 Reward: 95.0\n",
      "Episode 1712 Reward: 91.0\n",
      "Episode 1713 Reward: 91.0\n",
      "Episode 1714 Reward: 95.0\n",
      "Episode 1715 Reward: 95.0\n",
      "Episode 1716 Reward: -390.0\n",
      "Episode 1717 Reward: -400.0\n",
      "Episode 1718 Reward: 38.0\n",
      "Episode 1719 Reward: 53.0\n",
      "Episode 1720 Reward: 95.0\n",
      "Episode 1721 Reward: 91.0\n",
      "Episode 1722 Reward: 95.0\n",
      "Episode 1723 Reward: 95.0\n",
      "Episode 1724 Reward: 95.0\n",
      "Episode 1725 Reward: 95.0\n",
      "Episode 1726 Reward: 95.0\n",
      "Episode 1727 Reward: 57.0\n",
      "Episode 1728 Reward: -395.0\n",
      "Episode 1729 Reward: -107.0\n",
      "Episode 1730 Reward: 95.0\n",
      "Episode 1731 Reward: 72.0\n",
      "Episode 1732 Reward: 95.0\n",
      "Timesteps: 45000, Policy Loss: 0.001586802582679514, Value Loss: 90.43052597045899, Entropy: 0.7122381865978241\n",
      "Episode 1733 Reward: 34.0\n",
      "Episode 1734 Reward: -395.0\n",
      "Episode 1735 Reward: 87.0\n",
      "Episode 1736 Reward: 95.0\n",
      "Episode 1737 Reward: 95.0\n",
      "Episode 1738 Reward: 95.0\n",
      "Episode 1739 Reward: 95.0\n",
      "Episode 1740 Reward: 95.0\n",
      "Episode 1741 Reward: 0.0\n",
      "Episode 1742 Reward: 95.0\n",
      "Episode 1743 Reward: -395.0\n",
      "Episode 1744 Reward: 95.0\n",
      "Episode 1745 Reward: -76.0\n",
      "Episode 1746 Reward: 95.0\n",
      "Episode 1747 Reward: -23.0\n",
      "Episode 1748 Reward: 95.0\n",
      "Episode 1749 Reward: 95.0\n",
      "Episode 1750 Reward: 95.0\n",
      "Episode 1751 Reward: 53.0\n",
      "Episode 1752 Reward: 45.0\n",
      "Episode 1753 Reward: 95.0\n",
      "Episode 1754 Reward: 95.0\n",
      "Episode 1755 Reward: -39.0\n",
      "Episode 1756 Reward: 32.0\n",
      "Episode 1757 Reward: -400.0\n",
      "Episode 1758 Reward: 95.0\n",
      "Episode 1759 Reward: 95.0\n",
      "Episode 1760 Reward: -385.0\n",
      "Episode 1761 Reward: 57.0\n",
      "Episode 1762 Reward: 95.0\n",
      "Episode 1763 Reward: 87.0\n",
      "Episode 1764 Reward: 95.0\n",
      "Episode 1765 Reward: -405.0\n",
      "Episode 1766 Reward: 95.0\n",
      "Episode 1767 Reward: 95.0\n",
      "Episode 1768 Reward: 52.0\n",
      "Episode 1769 Reward: 95.0\n",
      "Episode 1770 Reward: 95.0\n",
      "Episode 1771 Reward: 95.0\n",
      "Episode 1772 Reward: 41.0\n",
      "Episode 1773 Reward: 95.0\n",
      "Episode 1774 Reward: -395.0\n",
      "Episode 1775 Reward: 95.0\n",
      "Episode 1776 Reward: -390.0\n",
      "Episode 1777 Reward: 32.0\n",
      "Episode 1778 Reward: 95.0\n",
      "Episode 1779 Reward: 76.0\n",
      "Episode 1780 Reward: 95.0\n",
      "Episode 1781 Reward: -400.0\n",
      "Episode 1782 Reward: 76.0\n",
      "Episode 1783 Reward: 83.0\n",
      "Episode 1784 Reward: 95.0\n",
      "Episode 1785 Reward: -400.0\n",
      "Episode 1786 Reward: 44.0\n",
      "Episode 1787 Reward: 68.0\n",
      "Episode 1788 Reward: -395.0\n",
      "Episode 1789 Reward: -38.0\n",
      "Episode 1790 Reward: 91.0\n",
      "Episode 1791 Reward: 38.0\n",
      "Episode 1792 Reward: 91.0\n",
      "Episode 1793 Reward: 95.0\n",
      "Episode 1794 Reward: 91.0\n",
      "Episode 1795 Reward: 95.0\n",
      "Episode 1796 Reward: 91.0\n",
      "Episode 1797 Reward: 91.0\n",
      "Episode 1798 Reward: 95.0\n",
      "Episode 1799 Reward: 95.0\n",
      "Episode 1800 Reward: 91.0\n",
      "Episode 1801 Reward: 95.0\n",
      "Episode 1802 Reward: 14.0\n",
      "Episode 1803 Reward: 95.0\n",
      "Episode 1804 Reward: 95.0\n",
      "Episode 1805 Reward: -400.0\n",
      "Episode 1806 Reward: 91.0\n",
      "Episode 1807 Reward: 95.0\n",
      "Episode 1808 Reward: 95.0\n",
      "Episode 1809 Reward: 91.0\n",
      "Episode 1810 Reward: 33.0\n",
      "Episode 1811 Reward: 57.0\n",
      "Episode 1812 Reward: -395.0\n",
      "Episode 1813 Reward: 67.0\n",
      "Episode 1814 Reward: 91.0\n",
      "Episode 1815 Reward: -390.0\n",
      "Episode 1816 Reward: 91.0\n",
      "Episode 1817 Reward: 95.0\n",
      "Episode 1818 Reward: 95.0\n",
      "Episode 1819 Reward: -385.0\n",
      "Episode 1820 Reward: 95.0\n",
      "Episode 1821 Reward: -62.0\n",
      "Episode 1822 Reward: 95.0\n",
      "Episode 1823 Reward: 14.0\n",
      "Episode 1824 Reward: 95.0\n",
      "Episode 1825 Reward: 95.0\n",
      "Episode 1826 Reward: 91.0\n",
      "Episode 1827 Reward: 95.0\n",
      "Episode 1828 Reward: 95.0\n",
      "Episode 1829 Reward: -395.0\n",
      "Episode 1830 Reward: 95.0\n",
      "Episode 1831 Reward: 68.0\n",
      "Episode 1832 Reward: 95.0\n",
      "Episode 1833 Reward: -395.0\n",
      "Episode 1834 Reward: 76.0\n",
      "Episode 1835 Reward: 95.0\n",
      "Episode 1836 Reward: -53.0\n",
      "Episode 1837 Reward: 95.0\n",
      "Episode 1838 Reward: 95.0\n",
      "Episode 1839 Reward: 34.0\n",
      "Episode 1840 Reward: 38.0\n",
      "Episode 1841 Reward: -395.0\n",
      "Episode 1842 Reward: 76.0\n",
      "Episode 1843 Reward: 95.0\n",
      "Episode 1844 Reward: 91.0\n",
      "Episode 1845 Reward: 95.0\n",
      "Episode 1846 Reward: -390.0\n",
      "Episode 1847 Reward: -400.0\n",
      "Episode 1848 Reward: 95.0\n",
      "Episode 1849 Reward: -405.0\n",
      "Episode 1850 Reward: 95.0\n",
      "Episode 1851 Reward: -57.0\n",
      "Episode 1852 Reward: 95.0\n",
      "Episode 1853 Reward: -395.0\n",
      "Episode 1854 Reward: 91.0\n",
      "Episode 1855 Reward: 87.0\n",
      "Episode 1856 Reward: 95.0\n",
      "Episode 1857 Reward: 91.0\n",
      "Episode 1858 Reward: 95.0\n",
      "Episode 1859 Reward: 95.0\n",
      "Episode 1860 Reward: 34.0\n",
      "Episode 1861 Reward: 95.0\n",
      "Episode 1862 Reward: 52.0\n",
      "Episode 1863 Reward: 95.0\n",
      "Episode 1864 Reward: 95.0\n",
      "Episode 1865 Reward: 95.0\n",
      "Episode 1866 Reward: 91.0\n",
      "Episode 1867 Reward: 95.0\n",
      "Episode 1868 Reward: 95.0\n",
      "Episode 1869 Reward: 95.0\n",
      "Episode 1870 Reward: 95.0\n",
      "Episode 1871 Reward: 95.0\n",
      "Episode 1872 Reward: 76.0\n",
      "Episode 1873 Reward: 95.0\n",
      "Episode 1874 Reward: 95.0\n",
      "Episode 1875 Reward: 95.0\n",
      "Episode 1876 Reward: -395.0\n",
      "Episode 1877 Reward: 95.0\n",
      "Episode 1878 Reward: 72.0\n",
      "Episode 1879 Reward: 91.0\n",
      "Episode 1880 Reward: -385.0\n",
      "Episode 1881 Reward: 91.0\n",
      "Episode 1882 Reward: -5.0\n",
      "Episode 1883 Reward: 95.0\n",
      "Episode 1884 Reward: 0.0\n",
      "Episode 1885 Reward: -395.0\n",
      "Episode 1886 Reward: 95.0\n",
      "Episode 1887 Reward: 95.0\n",
      "Episode 1888 Reward: 76.0\n",
      "Episode 1889 Reward: 95.0\n",
      "Episode 1890 Reward: 14.0\n",
      "Episode 1891 Reward: -35.0\n",
      "Episode 1892 Reward: -395.0\n",
      "Episode 1893 Reward: 95.0\n",
      "Episode 1894 Reward: 87.0\n",
      "Episode 1895 Reward: 91.0\n",
      "Episode 1896 Reward: 95.0\n",
      "Episode 1897 Reward: 95.0\n",
      "Episode 1898 Reward: 95.0\n",
      "Episode 1899 Reward: -62.0\n",
      "Episode 1900 Reward: -380.0\n",
      "Episode 1901 Reward: -390.0\n",
      "Episode 1902 Reward: 95.0\n",
      "Episode 1903 Reward: 95.0\n",
      "Episode 1904 Reward: 95.0\n",
      "Episode 1905 Reward: 95.0\n",
      "Episode 1906 Reward: -15.0\n",
      "Episode 1907 Reward: 91.0\n",
      "Episode 1908 Reward: 95.0\n",
      "Episode 1909 Reward: 49.0\n",
      "Episode 1910 Reward: -105.0\n",
      "Timesteps: 48000, Policy Loss: 0.005375736536489484, Value Loss: 106.5524673461914, Entropy: 0.7365272581577301\n",
      "Episode 1911 Reward: -390.0\n",
      "Episode 1912 Reward: 95.0\n",
      "Episode 1913 Reward: 95.0\n",
      "Episode 1914 Reward: 91.0\n",
      "Episode 1915 Reward: -390.0\n",
      "Episode 1916 Reward: -149.0\n",
      "Episode 1917 Reward: 91.0\n",
      "Episode 1918 Reward: -395.0\n",
      "Episode 1919 Reward: 67.0\n",
      "Episode 1920 Reward: 79.0\n",
      "Episode 1921 Reward: -395.0\n",
      "Episode 1922 Reward: 95.0\n",
      "Episode 1923 Reward: 91.0\n",
      "Episode 1924 Reward: -99.0\n",
      "Episode 1925 Reward: -400.0\n",
      "Episode 1926 Reward: -395.0\n",
      "Episode 1927 Reward: -390.0\n",
      "Episode 1928 Reward: 95.0\n",
      "Episode 1929 Reward: 95.0\n",
      "Episode 1930 Reward: -395.0\n",
      "Episode 1931 Reward: -395.0\n",
      "Episode 1932 Reward: -57.0\n",
      "Episode 1933 Reward: 91.0\n",
      "Episode 1934 Reward: -400.0\n",
      "Episode 1935 Reward: -400.0\n",
      "Episode 1936 Reward: 95.0\n",
      "Episode 1937 Reward: 95.0\n",
      "Episode 1938 Reward: 48.0\n",
      "Episode 1939 Reward: 95.0\n",
      "Episode 1940 Reward: 95.0\n",
      "Episode 1941 Reward: -400.0\n",
      "Episode 1942 Reward: 95.0\n",
      "Episode 1943 Reward: 95.0\n",
      "Episode 1944 Reward: 57.0\n",
      "Episode 1945 Reward: 72.0\n",
      "Episode 1946 Reward: -405.0\n",
      "Episode 1947 Reward: -390.0\n",
      "Episode 1948 Reward: 95.0\n",
      "Episode 1949 Reward: 95.0\n",
      "Episode 1950 Reward: -400.0\n",
      "Episode 1951 Reward: 95.0\n",
      "Episode 1952 Reward: 95.0\n",
      "Episode 1953 Reward: 33.0\n",
      "Episode 1954 Reward: 95.0\n",
      "Episode 1955 Reward: 91.0\n",
      "Episode 1956 Reward: 95.0\n",
      "Episode 1957 Reward: 91.0\n",
      "Episode 1958 Reward: 95.0\n",
      "Episode 1959 Reward: 95.0\n",
      "Episode 1960 Reward: 91.0\n",
      "Episode 1961 Reward: -395.0\n",
      "Episode 1962 Reward: 71.0\n",
      "Episode 1963 Reward: 95.0\n",
      "Episode 1964 Reward: 95.0\n",
      "Episode 1965 Reward: 72.0\n",
      "Episode 1966 Reward: 91.0\n",
      "Episode 1967 Reward: 95.0\n",
      "Episode 1968 Reward: -148.0\n",
      "Episode 1969 Reward: 91.0\n",
      "Episode 1970 Reward: 95.0\n",
      "Episode 1971 Reward: 14.0\n",
      "Episode 1972 Reward: -62.0\n",
      "Episode 1973 Reward: 95.0\n",
      "Episode 1974 Reward: 95.0\n",
      "Episode 1975 Reward: -400.0\n",
      "Episode 1976 Reward: 95.0\n",
      "Episode 1977 Reward: 87.0\n",
      "Episode 1978 Reward: 14.0\n",
      "Episode 1979 Reward: -390.0\n",
      "Episode 1980 Reward: 95.0\n",
      "Episode 1981 Reward: -14.0\n",
      "Episode 1982 Reward: 95.0\n",
      "Episode 1983 Reward: -405.0\n",
      "Episode 1984 Reward: -385.0\n",
      "Episode 1985 Reward: 95.0\n",
      "Episode 1986 Reward: 95.0\n",
      "Episode 1987 Reward: -395.0\n",
      "Episode 1988 Reward: 95.0\n",
      "Episode 1989 Reward: -400.0\n",
      "Episode 1990 Reward: 95.0\n",
      "Episode 1991 Reward: 95.0\n",
      "Episode 1992 Reward: 91.0\n",
      "Episode 1993 Reward: -395.0\n",
      "Episode 1994 Reward: 28.0\n",
      "Episode 1995 Reward: -400.0\n",
      "Episode 1996 Reward: 95.0\n",
      "Episode 1997 Reward: 95.0\n",
      "Episode 1998 Reward: 95.0\n",
      "Episode 1999 Reward: -405.0\n",
      "Episode 2000 Reward: 91.0\n",
      "Episode 2001 Reward: -395.0\n",
      "Episode 2002 Reward: -390.0\n",
      "Episode 2003 Reward: 19.0\n",
      "Episode 2004 Reward: 95.0\n",
      "Episode 2005 Reward: -19.0\n",
      "Episode 2006 Reward: 95.0\n",
      "Episode 2007 Reward: 91.0\n",
      "Episode 2008 Reward: 95.0\n",
      "Episode 2009 Reward: 95.0\n",
      "Episode 2010 Reward: 95.0\n",
      "Episode 2011 Reward: 95.0\n",
      "Episode 2012 Reward: 95.0\n",
      "Episode 2013 Reward: 95.0\n",
      "Episode 2014 Reward: 95.0\n",
      "Episode 2015 Reward: -395.0\n",
      "Episode 2016 Reward: -119.0\n",
      "Episode 2017 Reward: 9.0\n",
      "Episode 2018 Reward: 87.0\n",
      "Episode 2019 Reward: -395.0\n",
      "Episode 2020 Reward: -100.0\n",
      "Episode 2021 Reward: -395.0\n",
      "Episode 2022 Reward: -243.0\n",
      "Episode 2023 Reward: 95.0\n",
      "Episode 2024 Reward: -400.0\n",
      "Episode 2025 Reward: -54.0\n",
      "Timesteps: 51000, Policy Loss: 0.0045057706683408584, Value Loss: 93.84187850952148, Entropy: 0.6456804752349854\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "env = VizDoomGym(render=False)\n",
    "agent = PPOAgent(env.action_space)\n",
    "run_name= \"basic_2\"\n",
    "ppo = PPO(\n",
    "    env=env,\n",
    "    agent=agent,\n",
    "    run_name=run_name)\n",
    "total_timesteps = 50000\n",
    "ppo.learn(total_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3ed67632-b0cc-4a7c-a3d3-b009d0e589d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'ppo_vizdoom_agent_{run_name}.pth'\n",
    "torch.save(agent.state_dict(), filename)\n",
    "basic_file_list.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2f56a120-ca49-4749-a08f-f31e7b9286ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 Reward: 95.0\n",
      "Average Reward over 5 episodes: 95.0\n",
      "Episode 2 Reward: 95.0\n",
      "Average Reward over 5 episodes: 95.0\n",
      "Episode 3 Reward: 95.0\n",
      "Average Reward over 5 episodes: 95.0\n",
      "Episode 4 Reward: 95.0\n",
      "Average Reward over 5 episodes: 95.0\n",
      "Episode 5 Reward: 95.0\n",
      "Average Reward over 5 episodes: 95.0\n"
     ]
    }
   ],
   "source": [
    "evaluate_policy(agent, env, trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa5bdb-1c71-40de-a18f-7ba011889cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/train_basic'\n",
    "LOG_DIR = './logs/log_basic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23ad2261-475a-41d0-a1dc-e2353fa67304",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = PPOCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "548fab95-0c2e-4503-9183-9df481f129d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "env = VizDoomGym()\n",
    "model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, learning_rate=0.0001, n_steps=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f60ca326-0009-4958-9284-cd7221e1edcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100000\u001b[39m, callback \u001b[38;5;241m=\u001b[39m callback)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps = 100000, callback = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "53d355a3-ebed-4354-9c24-dfcf84b7965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "152ca637-cf0a-48fc-8c95-f905069d66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
